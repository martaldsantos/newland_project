{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RtChpBIwnLQ"
   },
   "source": [
    "# **Initial Steps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:17:44.804922Z",
     "start_time": "2020-12-12T11:17:44.796943Z"
    },
    "id": "ZZshs59W4FQR"
   },
   "outputs": [],
   "source": [
    "#from pydrive.auth import GoogleAuth\n",
    "#from pydrive.drive import GoogleDrive\n",
    "#from google.colab import auth\n",
    "#from oauth2client.client import GoogleCredentials\n",
    "\n",
    "#auth.authenticate_user()\n",
    "#gauth = GoogleAuth()\n",
    "#gauth.credentials = GoogleCredentials.get_application_default()\n",
    "#drive = GoogleDrive(gauth)\n",
    "\n",
    "#downloaded = drive.CreateFile({'id':\"10TVpC4_CV-h4o2U3P7KjGdvbsiuFFnkN\"})   # replace the id with id of file you want to access\n",
    "#downloaded.GetContentFile('Train.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "U-78uRpS3VJn"
   },
   "source": [
    "### Libraries, Packages and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:17:45.006384Z",
     "start_time": "2020-12-12T11:17:44.991424Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-h_iFQoV6dAa",
    "outputId": "8204dc82-d566-4c82-f05a-2fbf3c2aca36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in d:\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (0.11.1)\n",
      "Requirement already satisfied: patsy>=0.5.1 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (1.5.0)\n",
      "Requirement already satisfied: pandas>=0.21.1 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (1.0.5)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.14.0 in d:\\anaconda3\\lib\\site-packages (from category_encoders) (1.18.5)\n",
      "Requirement already satisfied: six in d:\\anaconda3\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytz>=2017.2 in d:\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in d:\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'D:\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in d:\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.23.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.16.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 20.3.1 is available.\n",
      "You should consider upgrading via the 'D:\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:17:51.367729Z",
     "start_time": "2020-12-12T11:17:45.110107Z"
    },
    "hidden": true,
    "id": "IuGGg6SC3VJn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "# from pandas_profiling import ProfileReport\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn import datasets\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "import category_encoders as ce\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import f_classif, chi2\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, KMeansSMOTE, ADASYN\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "# for better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "LfZNC8kO3VJn"
   },
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:17:51.475996Z",
     "start_time": "2020-12-12T11:17:51.388738Z"
    },
    "hidden": true,
    "id": "oMCQQSU_3VJn"
   },
   "outputs": [],
   "source": [
    "def birthday_to_age(df, column, new_column):\n",
    "    '''\n",
    "    This function creates a column representing the difference in years from a given birth year column values\n",
    "    Having into account that we are on the year 2048\n",
    "    '''\n",
    "    \n",
    "    df[new_column] = df[column].map(lambda x : 2048 - x)\n",
    "    \n",
    "def questionmark_to_nan(df, column):\n",
    "    '''\n",
    "    This function turns a binary variable with missing values as '?' in NaN\n",
    "    It needs as input the dataframe and the column name \n",
    "    (column name needs to be between '')\n",
    "    '''\n",
    "    df[column] = df[column].map(lambda x: np.nan if x == '?' else x)\n",
    "    \n",
    "def ohe(df, column_list):\n",
    "    ohc = OneHotEncoder(sparse = False)\n",
    "    ohc_feat = ohc.fit_transform(df[column_list])\n",
    "    ohc_feat_names = ohc.get_feature_names()\n",
    "    ohc_df = pd.DataFrame(ohc_feat, index = df.index, columns = ohc_feat_names)\n",
    "    return ohc_df\n",
    "\n",
    "def hist_box_maker(df,titl, num_of_rows, figx, figy):\n",
    "    \n",
    "    fig, axes = plt.subplots(num_of_rows, ceil((len(df.columns)*2)/num_of_rows), figsize=(figx, figy))\n",
    "    temp = (list(df.columns)*2)\n",
    "    temp.sort()\n",
    "    # Plot data\n",
    "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
    "    i = 0 \n",
    "    for ax, feat in zip(axes.flatten(), temp):\n",
    "        \n",
    "        if i%2 == 0:\n",
    "            ax.hist(df[feat], bins = 50)\n",
    "            ax.set_title(feat, y=-0.13)\n",
    "            pltiswork=feat\n",
    "            \n",
    "        else:\n",
    "            sns.boxplot(x=df[pltiswork], ax = ax)\n",
    "        \n",
    "        i+=1\n",
    "            \n",
    "    # Layout\n",
    "    # Add a centered title to the figure:\n",
    "    title = titl\n",
    "\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.show()# All Numer\n",
    "    \n",
    "    \n",
    "def plot_importance(coef, name):\n",
    "    imp_coef = coef.sort_values()\n",
    "    plt.figure(figsize = (8,10))\n",
    "    imp_coef.plot(kind = 'barh')\n",
    "    plt.title('Feature Importance Using ' + name + ' Regression')\n",
    "    plt.show()\n",
    "    \n",
    "def metrics(y_train, pred_train , y_val, pred_val):\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                     TRAIN                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_train, pred_train))\n",
    "    print(confusion_matrix(y_train, pred_train))\n",
    "\n",
    "\n",
    "    print('___________________________________________________________________________________________________________')\n",
    "    print('                                                VALIDATION                                                 ')\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    print(confusion_matrix(y_val, pred_val))\n",
    "def hist_box_maker(df,titl, num_of_rows, figx, figy):\n",
    "    \n",
    "    fig, axes = plt.subplots(num_of_rows, ceil((len(df.columns)*2)/num_of_rows), figsize=(figx, figy))\n",
    "    temp = (list(df.columns)*2)\n",
    "    temp.sort()\n",
    "    # Plot data\n",
    "    # Iterate across axes objects and associate each histogram (hint: use the ax.hist() instead of plt.hist()):\n",
    "    i = 0 \n",
    "    for ax, feat in zip(axes.flatten(), temp):\n",
    "        \n",
    "        if i%2 == 0:\n",
    "            ax.hist(df[feat], bins = 100)\n",
    "            ax.set_title(feat, y=-0.13)\n",
    "            pltiswork=feat\n",
    "            \n",
    "        else:\n",
    "            sns.boxplot(x=df[pltiswork], ax = ax)\n",
    "        \n",
    "        i+=1\n",
    "            \n",
    "    # Layout\n",
    "    # Add a centered title to the figure:\n",
    "    title = titl\n",
    "\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    plt.show()# All Numeric Variables' Box Plots in one figure\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "B1Ka7i_z3VJn"
   },
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.211682Z",
     "start_time": "2020-12-12T11:17:51.487965Z"
    },
    "hidden": true,
    "id": "oe2aTIuy3VJo"
   },
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"Train.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "CJIExRy53VJo"
   },
   "source": [
    "# **Data Inspection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.241603Z",
     "start_time": "2020-12-12T11:18:00.214674Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "hidden": true,
    "id": "XwTqAtDG3VJo",
    "outputId": "7b0ad901-ddc9-4d0b-e205-9f145e0a3187"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITIZEN_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Native Continent</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Lives with</th>\n",
       "      <th>Base Area</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Years of Education</th>\n",
       "      <th>Employment Sector</th>\n",
       "      <th>Role</th>\n",
       "      <th>Working Hours per week</th>\n",
       "      <th>Money Received</th>\n",
       "      <th>Ticket Price</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12486</td>\n",
       "      <td>Mr. Adam Glover</td>\n",
       "      <td>July 1,2003</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Married</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Northbury</td>\n",
       "      <td>High School + PostGraduation</td>\n",
       "      <td>13</td>\n",
       "      <td>Private Sector - Services</td>\n",
       "      <td>Repair &amp; constructions</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>2273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12487</td>\n",
       "      <td>Mr. Cameron McDonald</td>\n",
       "      <td>January 25,2006</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Married</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Northbury</td>\n",
       "      <td>Professional School</td>\n",
       "      <td>12</td>\n",
       "      <td>Public Sector - Others</td>\n",
       "      <td>Repair &amp; constructions</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12488</td>\n",
       "      <td>Mr. Keith Davidson</td>\n",
       "      <td>May 10,2009</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Married</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Northbury</td>\n",
       "      <td>Professional School</td>\n",
       "      <td>12</td>\n",
       "      <td>Private Sector - Services</td>\n",
       "      <td>Sales</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>2321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12489</td>\n",
       "      <td>Mr. Alexander Gill</td>\n",
       "      <td>March 25,1985</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Married</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Northbury</td>\n",
       "      <td>High School - 2nd Cycle</td>\n",
       "      <td>11</td>\n",
       "      <td>Private Sector - Services</td>\n",
       "      <td>Security</td>\n",
       "      <td>37</td>\n",
       "      <td>5395</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12490</td>\n",
       "      <td>Mr. Neil Piper</td>\n",
       "      <td>May 29,2015</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Single</td>\n",
       "      <td>Other Family</td>\n",
       "      <td>Northbury</td>\n",
       "      <td>PhD</td>\n",
       "      <td>21</td>\n",
       "      <td>Self-Employed (Individual)</td>\n",
       "      <td>Professor</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CITIZEN_ID                  Name          Birthday Native Continent  \\\n",
       "0       12486       Mr. Adam Glover       July 1,2003           Europe   \n",
       "1       12487  Mr. Cameron McDonald   January 25,2006           Europe   \n",
       "2       12488    Mr. Keith Davidson       May 10,2009           Europe   \n",
       "3       12489    Mr. Alexander Gill     March 25,1985           Europe   \n",
       "4       12490        Mr. Neil Piper       May 29,2015           Europe   \n",
       "\n",
       "  Marital Status    Lives with  Base Area               Education Level  \\\n",
       "0        Married          Wife  Northbury  High School + PostGraduation   \n",
       "1        Married          Wife  Northbury           Professional School   \n",
       "2        Married          Wife  Northbury           Professional School   \n",
       "3        Married          Wife  Northbury       High School - 2nd Cycle   \n",
       "4         Single  Other Family  Northbury                           PhD   \n",
       "\n",
       "   Years of Education           Employment Sector                    Role  \\\n",
       "0                  13  Private Sector - Services   Repair & constructions   \n",
       "1                  12      Public Sector - Others  Repair & constructions   \n",
       "2                  12  Private Sector - Services                    Sales   \n",
       "3                  11  Private Sector - Services                 Security   \n",
       "4                  21  Self-Employed (Individual)               Professor   \n",
       "\n",
       "   Working Hours per week  Money Received  Ticket Price  Income  \n",
       "0                      40               0          2273       1  \n",
       "1                      40               0             0       1  \n",
       "2                      46               0          2321       1  \n",
       "3                      37            5395             0       1  \n",
       "4                      45               0             0       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head() #Data was imported correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.272519Z",
     "start_time": "2020-12-12T11:18:00.247590Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "rP-zf8Cf3VJp",
    "outputId": "cbf65e17-6121-4fa3-ac4e-f5b7ebdabd96",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CITIZEN_ID                 int64\n",
       "Name                      object\n",
       "Birthday                  object\n",
       "Native Continent          object\n",
       "Marital Status            object\n",
       "Lives with                object\n",
       "Base Area                 object\n",
       "Education Level           object\n",
       "Years of Education         int64\n",
       "Employment Sector         object\n",
       "Role                      object\n",
       "Working Hours per week     int64\n",
       "Money Received             int64\n",
       "Ticket Price               int64\n",
       "Income                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No column seems to have, for now, a wrong dtype, except Birthday\n",
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.318105Z",
     "start_time": "2020-12-12T11:18:00.274514Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "zcY0LrLD6I5a",
    "outputId": "5a1c979d-792c-42f2-c8e8-67625e9b9bfe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITIZEN_ID</th>\n",
       "      <th>Years of Education</th>\n",
       "      <th>Working Hours per week</th>\n",
       "      <th>Money Received</th>\n",
       "      <th>Ticket Price</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "      <td>22400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23685.500000</td>\n",
       "      <td>13.173884</td>\n",
       "      <td>40.483795</td>\n",
       "      <td>1324.915357</td>\n",
       "      <td>109.145313</td>\n",
       "      <td>0.237098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6466.467351</td>\n",
       "      <td>2.512451</td>\n",
       "      <td>12.370921</td>\n",
       "      <td>9227.771813</td>\n",
       "      <td>500.208904</td>\n",
       "      <td>0.425313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12486.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>18085.750000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23685.500000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>29285.250000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34885.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>122999.000000</td>\n",
       "      <td>5358.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CITIZEN_ID  Years of Education  Working Hours per week  \\\n",
       "count  22400.000000        22400.000000            22400.000000   \n",
       "mean   23685.500000           13.173884               40.483795   \n",
       "std     6466.467351            2.512451               12.370921   \n",
       "min    12486.000000            2.000000                1.000000   \n",
       "25%    18085.750000           12.000000               40.000000   \n",
       "50%    23685.500000           13.000000               40.000000   \n",
       "75%    29285.250000           15.000000               45.000000   \n",
       "max    34885.000000           21.000000               99.000000   \n",
       "\n",
       "       Money Received  Ticket Price        Income  \n",
       "count    22400.000000  22400.000000  22400.000000  \n",
       "mean      1324.915357    109.145313      0.237098  \n",
       "std       9227.771813    500.208904      0.425313  \n",
       "min          0.000000      0.000000      0.000000  \n",
       "25%          0.000000      0.000000      0.000000  \n",
       "50%          0.000000      0.000000      0.000000  \n",
       "75%          0.000000      0.000000      0.000000  \n",
       "max     122999.000000   5358.000000      1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.350019Z",
     "start_time": "2020-12-12T11:18:00.322094Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "yaL7-l6V3VJp",
    "outputId": "762dcb4a-b1f4-4658-8b8d-72e5803958f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CITIZEN_ID                0\n",
       "Name                      0\n",
       "Birthday                  0\n",
       "Native Continent          0\n",
       "Marital Status            0\n",
       "Lives with                0\n",
       "Base Area                 0\n",
       "Education Level           0\n",
       "Years of Education        0\n",
       "Employment Sector         0\n",
       "Role                      0\n",
       "Working Hours per week    0\n",
       "Money Received            0\n",
       "Ticket Price              0\n",
       "Income                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum() #No \"immediate\" missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "1vJQ4A6F3VJq"
   },
   "source": [
    "### Data Treatment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "Fr_OG5wj3VJq"
   },
   "source": [
    "#### Categorical Variables Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "4UnnTZXI3VJq"
   },
   "source": [
    "Lets start to treat the object type variables.\n",
    "\n",
    "Remember that no variables seemed to show missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.396929Z",
     "start_time": "2020-12-12T11:18:00.354009Z"
    },
    "id": "QTsjxYLAZ62V"
   },
   "outputs": [],
   "source": [
    "for i in [\"Name\", \"Native Continent\", \"Marital Status\", \"Lives with\", \"Base Area\", \"Education Level\", \"Employment Sector\", \"Role\"]:\n",
    "    train[i] = train[i].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.411863Z",
     "start_time": "2020-12-12T11:18:00.399894Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xY1b3qF2F0RJ",
    "outputId": "9788477d-00b8-4cb3-c81d-471cf1a40219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CITIZEN_ID                 int64\n",
       "Name                      object\n",
       "Birthday                  object\n",
       "Native Continent          object\n",
       "Marital Status            object\n",
       "Lives with                object\n",
       "Base Area                 object\n",
       "Education Level           object\n",
       "Years of Education         int64\n",
       "Employment Sector         object\n",
       "Role                      object\n",
       "Working Hours per week     int64\n",
       "Money Received             int64\n",
       "Ticket Price               int64\n",
       "Income                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All seems fine.\n",
    "However in order to use Native Continent on our models we will need to later perform one hot encoding.\n",
    "We can't use label encoding since the categories aren't ordered and we would be inducing orders or hierarchies were they don't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.426824Z",
     "start_time": "2020-12-12T11:18:00.413859Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "mJ7vYYfQ3VJq",
    "outputId": "2e788931-61f8-4d33-b20d-b9b11b0cd7c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Europe     19111\n",
       "Africa      2187\n",
       "Asia         699\n",
       "America      219\n",
       "Oceania      184\n",
       "Name: Native Continent, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Native Continent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values can be turned into binary variables which describe if the person is married, not married (anymore), or never married.\n",
    "This will allow us to have a better significance in our resuls (meaning, not a huge amount of 0s in binary variables), which we would\n",
    "have if we proceed to make one hot encoding right now. \n",
    "We will make this change later in the feature engineering step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.441783Z",
     "start_time": "2020-12-12T11:18:00.428819Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "R_XuC6MQ3VJq",
    "outputId": "127f4c4b-f76b-4ace-db8a-8e84cd6b707a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Married                         10219\n",
       "Single                           7416\n",
       "Divorced                         3072\n",
       "Separated                         699\n",
       "Widow                             696\n",
       "Married - Spouse Missing          284\n",
       "Married - Spouse in the Army       14\n",
       "Name: Marital Status, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Marital Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These values can be turned into binary variables. For being able to do so, we will primarily turn the values \"Husband\" and \"Wife\" in \"Spouse\" and \"Other Family\"\n",
    "and \"Other relatives\" in only 1 value as they seem to have the same meaning.\n",
    "We will make this change later in the feature engineering step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.457767Z",
     "start_time": "2020-12-12T11:18:00.444780Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "E6gaQI393VJr",
    "outputId": "f35538a2-6e78-4383-d74c-86ac5a174571"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wife               9012\n",
       "Other Family       5777\n",
       "Children           3519\n",
       "Alone              2362\n",
       "Husband            1049\n",
       "Other relatives     681\n",
       "Name: Lives with, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Lives with'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have '?' values, wich are clearly missing values, so we have to turn them into ones.\n",
    "With the high number of missing values, we will probably need to use techniques to fill missing values, for example, the KNN\n",
    "We also believe we cannot make one hot encoding in this variable otherwise we would create too many variables and they would loose their significance.\n",
    "However, it is important to highlight that we have a lot of observations with the value Northbury, which means that if we have to make only a binary column with this variable it will have a good representation on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.487665Z",
     "start_time": "2020-12-12T11:18:00.462730Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "YjN_pMxi3VJr",
    "outputId": "f7c83577-493f-4c0b-cd20-d7f1509f6248"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Northbury        20074\n",
       "Fanfoss            443\n",
       "?                  395\n",
       "Alverton           135\n",
       "Butterpond          96\n",
       "Watford             83\n",
       "Auchenshuggle       80\n",
       "Pran                77\n",
       "Sharnwick           70\n",
       "Aroonshire          64\n",
       "Laewaes             63\n",
       "Fool's March        59\n",
       "Eelry               56\n",
       "Wigston             56\n",
       "Sharpton            54\n",
       "Lanercost           52\n",
       "Cherrytown          51\n",
       "Aerilon             45\n",
       "King's Watch        44\n",
       "Bellmoral           40\n",
       "Kirkwall            40\n",
       "Knife's Edge        37\n",
       "Laenteglos          32\n",
       "Tranmere            30\n",
       "Drumchapel          25\n",
       "Aberuthven          23\n",
       "Orilon              22\n",
       "Kald                19\n",
       "Carlisle            18\n",
       "MillerVille         17\n",
       "Willesden           16\n",
       "Lewes               16\n",
       "Conriston           12\n",
       "Marnmouth           11\n",
       "Middlesbrough       10\n",
       "Mensfield            9\n",
       "Woodpine             9\n",
       "Bellenau             8\n",
       "Redwick Bush         8\n",
       "Ironforge            1\n",
       "Name: Base Area, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Base Area'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories seem to be good! We believe that a distinction as deep as the one presented is not needed, and so, we will\n",
    "group some variables as the latest education a person has received.\n",
    "As we are dealing with Ordinal data, meaning, the variables have a natural order, for example, a PhD is valued higher than a high school degree, we will create a variable that contains the categories representing the education qualification, in integer values, as the algorithm can process these values as an order.\n",
    "We will make this change later in the feature engineering step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.502619Z",
     "start_time": "2020-12-12T11:18:00.490654Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "yvFiuvLl3VJr",
    "outputId": "90c3c284-b27b-48fb-f096-8414ece8dffa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Professional School                     7232\n",
       "High School + PostGraduation            4994\n",
       "Bachelors + PostGraduation              3696\n",
       "Masters                                 1193\n",
       "Professional School + PostGraduation     953\n",
       "High School - 2nd Cycle                  809\n",
       "Bachelors                                735\n",
       "High School - 1st Cycle                  649\n",
       "Middle School - 2nd Cycle                432\n",
       "Masters + PostGraduation                 397\n",
       "Middle School Complete                   342\n",
       "PhD                                      289\n",
       "High School Complete                     287\n",
       "Middle School - 1st Cycle                237\n",
       "Primary School                           122\n",
       "Preschool                                 33\n",
       "Name: Education Level, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Education Level'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the same missing values problem as before, meaning, when there is missing data it is represented by a \"?\".\n",
    "The categories have information about big groups of values (private sector, public sector, etc), so we will retrieve this information in a more correct and larger way.\n",
    "After doing so, we will probably have to reach to some type of data encoding technique in order to be able to use this information in our model.\n",
    "We will make this change later in the feature engineering step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.533537Z",
     "start_time": "2020-12-12T11:18:00.504617Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "90lK7yY43VJr",
    "outputId": "9fcc8888-acc8-40af-a804-415b92af3412"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private Sector - Services     15599\n",
       "Self-Employed (Individual)     1764\n",
       "Public Sector - Others         1419\n",
       "?                              1264\n",
       "Private Sector - Others         880\n",
       "Self-Employed (Company)         763\n",
       "Public Sector - Government      692\n",
       "Unemployed                       12\n",
       "Never Worked                      7\n",
       "Name: Employment Sector, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Employment Sector'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has the same missing values problem as before, meaning, when there is missing data it is represented by a \"?\".\n",
    "The grouping of information (in order to be able to have encoding) in this variable is difficult to tackle.\n",
    "We will probably use the sectors of the economy to make some type of encoding in this variable.\n",
    "We will make this change later in the feature engineering step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.549495Z",
     "start_time": "2020-12-12T11:18:00.535534Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "f5UfPGDT3VJs",
    "outputId": "3d168a3a-65aa-41b6-b331-f0c94257e6b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Professor                         2849\n",
       "Management                        2797\n",
       "Repair & constructions            2795\n",
       "Administratives                   2608\n",
       "Sales                             2531\n",
       "Other services                    2287\n",
       "Machine Operators & Inspectors    1384\n",
       "?                                 1271\n",
       "Transports                        1071\n",
       "Cleaners & Handlers                922\n",
       "Agriculture and Fishing            702\n",
       "IT                                 626\n",
       "Security                           450\n",
       "Household Services                 102\n",
       "Army                                 5\n",
       "Name: Role, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Role'].value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the name is not very important in our analysis, we will proceed on removing the first word from the name, meaning, the gender the person identifies with and we will create a variable with information about the gender.\n",
    "We will make this change later in the feature engineering step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.564453Z",
     "start_time": "2020-12-12T11:18:00.551489Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "6FPwVdA-3VJs",
    "outputId": "2c6ac6d0-ce6f-4082-f6b7-fbc714ff0a27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Mr. Adam Glover\n",
       "1    Mr. Cameron McDonald\n",
       "2      Mr. Keith Davidson\n",
       "3      Mr. Alexander Gill\n",
       "4          Mr. Neil Piper\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Name'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly some transformations are needed, if we want to use this variable we will have to do some engineering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.579414Z",
     "start_time": "2020-12-12T11:18:00.566449Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "KGj0j7Ei3VJs",
    "outputId": "df77f9ee-bfaf-46a2-e066-b617d2e0def9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         July 1,2003\n",
       "1     January 25,2006\n",
       "2         May 10,2009\n",
       "3       March 25,1985\n",
       "4         May 29,2015\n",
       "Name: Birthday, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Birthday'].head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.675157Z",
     "start_time": "2020-12-12T11:18:00.582408Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tcuYTNyK6oag",
    "outputId": "cab55fcc-4d3a-4044-f34f-d45529e694d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Turning the \"?\" in missing value np.nan\n",
    "questionmark_to_nan(train, 'Base Area') \n",
    "questionmark_to_nan(train, 'Employment Sector') \n",
    "questionmark_to_nan(train, 'Role') \n",
    "\n",
    "#Checking whether there are more categorical variables with \"?\" values\n",
    "for i in [\"Name\", \"Native Continent\", \"Marital Status\", \"Lives with\", \"Base Area\", \"Education Level\", \"Employment Sector\", \"Role\"]:\n",
    "  print(train[i].str.contains('?', regex = False).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "fet4vQdL3VJt"
   },
   "source": [
    "#### Numeric Variables Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "pchXufJ43VJt"
   },
   "source": [
    "Since no variables showed *immediate* missing values, on the variables whose data type is float or int, we know that we won't have the problem of '?' missing values, otherwise the variables would be of object data type.\n",
    "\n",
    "However we still have to check these variables to know if there are some immediate incoherences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.691115Z",
     "start_time": "2020-12-12T11:18:00.676155Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "lnuKhL4U3VJt",
    "outputId": "697c6007-bc1e-4d3b-87b8-14ee3c0f2262"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CITIZEN_ID                 int64\n",
       "Name                      object\n",
       "Birthday                  object\n",
       "Native Continent          object\n",
       "Marital Status            object\n",
       "Lives with                object\n",
       "Base Area                 object\n",
       "Education Level           object\n",
       "Years of Education         int64\n",
       "Employment Sector         object\n",
       "Role                      object\n",
       "Working Hours per week     int64\n",
       "Money Received             int64\n",
       "Ticket Price               int64\n",
       "Income                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.736994Z",
     "start_time": "2020-12-12T11:18:00.693111Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "GkbSn6gA3VJt",
    "outputId": "28d68ead-fae7-45f7-eca9-7c92ae6caf4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No repeated Citizen ID's\n",
    "(train['CITIZEN_ID'].value_counts()>1).sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtMeNCzhJgux"
   },
   "source": [
    "**Assumption:**If the Citizen ID follows the normal order of atribution of ID after being recognized the citizenship, we know which citizens were the first to arrive, as their ID's will have a smaller value.\n",
    "\n",
    "O q fazemos em relação a isto????????????????????????????????????????????????????????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.751953Z",
     "start_time": "2020-12-12T11:18:00.738988Z"
    },
    "hidden": true,
    "id": "95rg-7bo3VJt",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#??????\n",
    "#train.drop(columns = ['CITIZEN_ID']).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "-UI_4cXH3VJt"
   },
   "source": [
    "# **Coherence Checks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.782871Z",
     "start_time": "2020-12-12T11:18:00.756939Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zKvkhUzdHeCz",
    "outputId": "d2cc894e-90bb-4928-aa81-cc30736f4559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative values:\n",
      "Years of Education : 0\n",
      "Working Hours per week : 0\n",
      "Money Received : 0\n",
      "Ticket Price : 0\n",
      "Income : 0\n"
     ]
    }
   ],
   "source": [
    "#It makes no sense to have negative values in the following numerical variables.\n",
    "print(\"Number of negative values:\")\n",
    "for i in [\"Years of Education\", \"Working Hours per week\", \"Money Received\", \"Ticket Price\", \"Income\"]:\n",
    "    print(i,\":\", ((train[i]<0).sum()))\n",
    "#All seems to be good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "MqNFuFx63VJt"
   },
   "source": [
    "No values below 0. For now everything looks fine.\n",
    "\n",
    "Considering the average, std and min and max values of *Years of Education* and *Working Hours per week*, there definitely seem to be some outliers, but we will check this with more detail later. Since most values of *Money Received* and *Ticket Price* are 0, we can't talk about its outliers right now. (Isto ja n faz sentido sem o describe, apagar?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.813787Z",
     "start_time": "2020-12-12T11:18:00.788855Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "vTcCsCQBM16g",
    "outputId": "6784d257-c46c-45d2-b924-7f4062546b6a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITIZEN_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Native Continent</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Lives with</th>\n",
       "      <th>Base Area</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Years of Education</th>\n",
       "      <th>Employment Sector</th>\n",
       "      <th>Role</th>\n",
       "      <th>Working Hours per week</th>\n",
       "      <th>Money Received</th>\n",
       "      <th>Ticket Price</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CITIZEN_ID, Name, Birthday, Native Continent, Marital Status, Lives with, Base Area, Education Level, Years of Education, Employment Sector, Role, Working Hours per week, Money Received, Ticket Price, Income]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Money Received']>0) & (train['Ticket Price']>0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvxCHiITM2DS"
   },
   "source": [
    "In the clause above we can see that there are no records that show people that have simultanously paid to go to Newland (belonging to Group C) and that have been paid to go to Newland (therefore belonging to Group B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.843707Z",
     "start_time": "2020-12-12T11:18:00.815782Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EludKndxN1JE",
    "outputId": "33b189bb-ccda-4446-b1b1-bac933dc45c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22400"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Money Received']>=0) & (train['Ticket Price']>=0)].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8UlfqH0N55j"
   },
   "source": [
    "This shows us that the data for these columns is correct! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITIZEN_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Native Continent</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Lives with</th>\n",
       "      <th>Base Area</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Years of Education</th>\n",
       "      <th>Employment Sector</th>\n",
       "      <th>Role</th>\n",
       "      <th>Working Hours per week</th>\n",
       "      <th>Money Received</th>\n",
       "      <th>Ticket Price</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CITIZEN_ID, Name, Birthday, Native Continent, Marital Status, Lives with, Base Area, Education Level, Years of Education, Employment Sector, Role, Working Hours per week, Money Received, Ticket Price, Income]\n",
       "Index: []"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Education Level'] == 'EQF4') & (train['Years of Education'] < 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITIZEN_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Native Continent</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Lives with</th>\n",
       "      <th>Base Area</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Years of Education</th>\n",
       "      <th>Employment Sector</th>\n",
       "      <th>Role</th>\n",
       "      <th>Working Hours per week</th>\n",
       "      <th>Money Received</th>\n",
       "      <th>Ticket Price</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CITIZEN_ID, Name, Birthday, Native Continent, Marital Status, Lives with, Base Area, Education Level, Years of Education, Employment Sector, Role, Working Hours per week, Money Received, Ticket Price, Income]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Education Level'] == 'EQF5') & (train['Years of Education'] < 12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITIZEN_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Native Continent</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Lives with</th>\n",
       "      <th>Base Area</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Years of Education</th>\n",
       "      <th>Employment Sector</th>\n",
       "      <th>Role</th>\n",
       "      <th>Working Hours per week</th>\n",
       "      <th>Money Received</th>\n",
       "      <th>Ticket Price</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CITIZEN_ID, Name, Birthday, Native Continent, Marital Status, Lives with, Base Area, Education Level, Years of Education, Employment Sector, Role, Working Hours per week, Money Received, Ticket Price, Income]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Education Level'] == 'EQF6') & (train['Years of Education'] < 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[(train['Education Level'] == 'EQF7') & (train['Years of Education'] < 17)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITIZEN_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>Native Continent</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Lives with</th>\n",
       "      <th>Base Area</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Years of Education</th>\n",
       "      <th>Employment Sector</th>\n",
       "      <th>Role</th>\n",
       "      <th>Working Hours per week</th>\n",
       "      <th>Money Received</th>\n",
       "      <th>Ticket Price</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CITIZEN_ID, Name, Birthday, Native Continent, Marital Status, Lives with, Base Area, Education Level, Years of Education, Employment Sector, Role, Working Hours per week, Money Received, Ticket Price, Income]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['Education Level'] == 'EQF8') & (train['Years of Education'] < 19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[train['Working hours per week'] > 168]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "id": "x04ImyMQ3VJt"
   },
   "source": [
    "# **Data Transformation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "Xejyuzup3VJt"
   },
   "source": [
    "#### Birthday to age transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "Lhae5MJm3VJt"
   },
   "source": [
    "We have the birthday of each person, but more usefull to estimate the model is their age.\n",
    "\n",
    "However before we calculate the age we have to do some transformations to the birthday variable.\n",
    "\n",
    "We will calculate the age having in to account that we are on the year 2048, and we don't know the current month or day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.858667Z",
     "start_time": "2020-12-12T11:18:00.845703Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "77gu2_gz3VJt",
    "outputId": "696aa362-77ca-4456-b192-17d9d4a000c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         July 1,2003\n",
       "1     January 25,2006\n",
       "2         May 10,2009\n",
       "3       March 25,1985\n",
       "4         May 29,2015\n",
       "Name: Birthday, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Birthday'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.983874Z",
     "start_time": "2020-12-12T11:18:00.862660Z"
    },
    "hidden": true,
    "id": "qX6kW-HE3VJt"
   },
   "outputs": [],
   "source": [
    "#First we extract the year of each birthday in to a new column\n",
    "train[\"YOB\"] = train['Birthday'].str.split(' ', n = 2, expand = True)[2].str.split(',', n = 1, expand = True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:00.999859Z",
     "start_time": "2020-12-12T11:18:00.985845Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "0IyCTnfV3VJt",
    "outputId": "c1428e46-c1b0-4c56-9aa0-fedb9903f223"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2003\n",
       "1    2006\n",
       "2    2009\n",
       "3    1985\n",
       "4    2015\n",
       "Name: YOB, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"YOB\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.014817Z",
     "start_time": "2020-12-12T11:18:01.002803Z"
    },
    "hidden": true,
    "id": "ypi9P3_h3VJt"
   },
   "outputs": [],
   "source": [
    "train['YOB'] = train['YOB'].astype('int64') #Turns year of birth in to dtype int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.044743Z",
     "start_time": "2020-12-12T11:18:01.016762Z"
    },
    "hidden": true,
    "id": "UOQEIp6q3VJt"
   },
   "outputs": [],
   "source": [
    "birthday_to_age(train, 'YOB', 'Age') #Turns year of birth to age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.075604Z",
     "start_time": "2020-12-12T11:18:01.046684Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "hidden": true,
    "id": "AegTHSOV3VJt",
    "outputId": "e9ebd9fe-2344-4e6b-805c-84dae423a037"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>22400.0</td>\n",
       "      <td>38.584866</td>\n",
       "      <td>13.651578</td>\n",
       "      <td>17.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count       mean        std   min   25%   50%   75%   max\n",
       "Age  22400.0  38.584866  13.651578  17.0  28.0  37.0  48.0  90.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[['Age']].describe().T #All seems fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.090566Z",
     "start_time": "2020-12-12T11:18:01.077600Z"
    },
    "hidden": true,
    "id": "gDZE4BwU3VJt"
   },
   "outputs": [],
   "source": [
    "#And we drop the columns we will no longer need\n",
    "train.drop(columns = ['Birthday', 'YOB'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age - Coherence Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CITIZEN_ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Native Continent</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Lives with</th>\n",
       "      <th>Base Area</th>\n",
       "      <th>Education Level</th>\n",
       "      <th>Years of Education</th>\n",
       "      <th>Employment Sector</th>\n",
       "      <th>Role</th>\n",
       "      <th>Working Hours per week</th>\n",
       "      <th>Money Received</th>\n",
       "      <th>Ticket Price</th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [CITIZEN_ID, Name, Native Continent, Marital Status, Lives with, Base Area, Education Level, Years of Education, Employment Sector, Role, Working Hours per week, Money Received, Ticket Price, Income, Age]\n",
       "Index: []"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['Age'] < 17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "Va9Ntv1a3VJt"
   },
   "source": [
    "#### Base Area -> Northbury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "UBrxfbPx3VJt"
   },
   "source": [
    "There are a lot of base areas, however most observations belong to Northbury, so instead of using one hot encoding and proceding with all the values, we will just proced with a variable that signals whether the person is of Northbury or not.\n",
    "\n",
    "MESMO ASSIM SERIA FIXE FAZER ONE HOT ENCODING E DPS FEATURE SELECTION PARA GARANTIR QUE REALMENTE SO A NORTHBURY DEVA FICAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.120486Z",
     "start_time": "2020-12-12T11:18:01.092560Z"
    },
    "hidden": true,
    "id": "mL2esext3VJt"
   },
   "outputs": [],
   "source": [
    "train['Northbury'] = train['Base Area'].map(lambda x: 1 if x == 'Northbury' else 0)\n",
    "\n",
    "#Não esquecer fazer inut NA antes disto\n",
    "#No entnto pode não ser necessário!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.136482Z",
     "start_time": "2020-12-12T11:18:01.122481Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "U7RrdBm83VJt",
    "outputId": "922bac7f-97ec-45f0-f7ab-825b7d35ecc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    20074\n",
       "0     2326\n",
       "Name: Northbury, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Northbury'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.152432Z",
     "start_time": "2020-12-12T11:18:01.139435Z"
    },
    "hidden": true,
    "id": "kwKw2_ll3VJt"
   },
   "outputs": [],
   "source": [
    "train.drop(columns = ['Base Area'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "cQggstrJ3VJu"
   },
   "source": [
    "#### Name -> Gender -> Male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "id": "UNig0NwH3VJu"
   },
   "source": [
    "It doesn't make sense to model using the different names in the dataset, however with the first byte of each one (for example: Mrs.) we can conclude quite easily the gender of each person. Having the gender we can then create a variable that signals all the males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.232186Z",
     "start_time": "2020-12-12T11:18:01.154395Z"
    },
    "hidden": true,
    "id": "fPpDsPeP3VJu"
   },
   "outputs": [],
   "source": [
    "train['Gender'] = train['Name'].str.split(' ', n = 1, expand = True)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.248147Z",
     "start_time": "2020-12-12T11:18:01.234189Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "TjBNfEa23VJu",
    "outputId": "67b2a54e-2252-485f-a7fd-11ffe58dea97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.     14971\n",
       "Mrs.     4117\n",
       "Miss     3312\n",
       "Name: Gender, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.280059Z",
     "start_time": "2020-12-12T11:18:01.253134Z"
    },
    "hidden": true,
    "id": "5gDiqz7Z3VJu"
   },
   "outputs": [],
   "source": [
    "train['Male'] = train['Gender'].map(lambda x: 1 if x == 'Mr.' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.296070Z",
     "start_time": "2020-12-12T11:18:01.282053Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "6WYInXrA3VJu",
    "outputId": "091ddec6-0feb-41c9-fa28-678f80f435ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    14971\n",
       "0     7429\n",
       "Name: Male, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Male'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.326934Z",
     "start_time": "2020-12-12T11:18:01.298011Z"
    },
    "hidden": true,
    "id": "gSOT0giy3VJu"
   },
   "outputs": [],
   "source": [
    "train.drop(columns = ['Name', 'Gender'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoDpxnU18KvV"
   },
   "source": [
    "### *Lives with* and *Marital Status*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.356854Z",
     "start_time": "2020-12-12T11:18:01.329925Z"
    },
    "id": "pQX1zt-r8OiF"
   },
   "outputs": [],
   "source": [
    "train['Marital Status'] = train['Marital Status'].map(lambda x: 'Married' if ((x == 'Married - Spouse Missing') | (x == 'Married - Spouse in the Army') ) else x)\n",
    "train['Marital Status'] = train['Marital Status'].map(lambda x: 'Not Married' if ((x == 'Divorced')  | (x == 'Separated') | (x == 'Widow')) else x)\n",
    "train['Marital Status'] = train['Marital Status'].map(lambda x: 'Never Married' if ((x == 'Single') ) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r0EnGFdY8cBb"
   },
   "source": [
    "There are no weird values and one hot encoding will be needed for the same reasons as in the previous variable.\n",
    "\n",
    "However some values seem to specific and have very little representation on the observations, so we will \"standardize\" this values: \"Married - Spouse Missing\" and \"Married - Spouse in the Army\" will be changed to \"Married\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3J29EFr48hgp"
   },
   "source": [
    "There is no point in discretizing between living with Wife or Husband, so we will aggregate it in Spouse. Same thing with other relatives and Other Family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.387770Z",
     "start_time": "2020-12-12T11:18:01.358850Z"
    },
    "id": "AfxjuYcR8Wul"
   },
   "outputs": [],
   "source": [
    "train['Lives with'] = train['Lives with'].map(lambda x: 'Spouse' if ((x == 'Wife') | (x == 'Husband')) else x)\n",
    "train['Lives with'] = train['Lives with'].map(lambda x: 'Other Family' if (x == 'Other relatives') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.402734Z",
     "start_time": "2020-12-12T11:18:01.389766Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnsphnDIK1if",
    "outputId": "4237f0a5-10d3-415e-c338-ca0e88cec612"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CITIZEN_ID                 int64\n",
       "Native Continent          object\n",
       "Marital Status            object\n",
       "Lives with                object\n",
       "Education Level           object\n",
       "Years of Education         int64\n",
       "Employment Sector         object\n",
       "Role                      object\n",
       "Working Hours per week     int64\n",
       "Money Received             int64\n",
       "Ticket Price               int64\n",
       "Income                     int64\n",
       "Age                        int64\n",
       "Northbury                  int64\n",
       "Male                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__sJDc_IMJrz"
   },
   "source": [
    "### Education Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zKUJRoWMV7nU"
   },
   "source": [
    "- https://en.wikipedia.org/wiki/Education_in_the_United_States\n",
    "- http://internacional.ipvc.pt/sites/default/files/Diagrama_SESP_EQF_PT1.pdf\n",
    "- https://europa.eu/europass/pt/description-eight-eqf-levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division will have to be made top to bottom. Meaning, if it appears \"Masters\" and \"PostGraduation\", we will treat first \"Masters\" to make sure we have the maximum education first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.417696Z",
     "start_time": "2020-12-12T11:18:01.406724Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FKox4VsCMMgR",
    "outputId": "8584fc03-57cb-478c-8aed-27afcc05ce5d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Professional School                     7232\n",
       "High School + PostGraduation            4994\n",
       "Bachelors + PostGraduation              3696\n",
       "Masters                                 1193\n",
       "Professional School + PostGraduation     953\n",
       "High School - 2nd Cycle                  809\n",
       "Bachelors                                735\n",
       "High School - 1st Cycle                  649\n",
       "Middle School - 2nd Cycle                432\n",
       "Masters + PostGraduation                 397\n",
       "Middle School Complete                   342\n",
       "PhD                                      289\n",
       "High School Complete                     287\n",
       "Middle School - 1st Cycle                237\n",
       "Primary School                           122\n",
       "Preschool                                 33\n",
       "Name: Education Level, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Education Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.479527Z",
     "start_time": "2020-12-12T11:18:01.420684Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AN2a_oBZMUo1",
    "outputId": "22cfebf0-bb7b-4499-95fd-ab5bf9042570"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostGraduation          9643\n",
       "Professional School     7232\n",
       "<HighSchool             2624\n",
       "Masters                 1590\n",
       "Bachelors                735\n",
       "PhD                      289\n",
       "High School Complete     287\n",
       "Name: Education Level, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solução 1 - Fazer por grupos que nós considerarmos certos. Aqui estão os que eu acho que ficam bem, mas é perfeitamente alterável\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'Masters' if (\"Masters\" in x) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'PostGraduation' if (\"PostGraduation\" in x) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'Incomplete High School' if ((x== \"High School - 2nd Cycle\") | (x== \"High School - 1st Cycle\")) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'Less than Middle School' if ((x==\"Middle School - 2nd Cycle\") | (x== \"Middle School - 1st Cycle\") | (x== \"Primary School\") |(x== \"Preschool\" )) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: '<HighSchool' if ((x==\"Incomplete High School\") | (x== \"Less than Middle School\") | (x== \"Middle School Complete\")) else x)\n",
    "train[\"Education Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.540427Z",
     "start_time": "2020-12-12T11:18:01.482518Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DeZU8v8IVSAn",
    "outputId": "31415365-c613-4c3f-f10c-6e60982aa208"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EQF7            11233\n",
       "EQF5             7232\n",
       "EQF3 or less     2624\n",
       "EQF6              735\n",
       "EQF8              289\n",
       "EQF4              287\n",
       "Name: Education Level, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solução 2 - Fazer por grupos instituidos pela UE (ver link acima). Se assim o fizermos, sabemos por exemplo que a professional school está acima da highschool!\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'EQF3 or less' if ((x==\"<HighSchool\")) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'EQF4' if ((x==\"High School Complete\")) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'EQF5' if ((x==\"Professional School\")) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'EQF6' if ((x==\"Bachelors\")) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'EQF7' if ((x==\"Masters\") | (x== \"PostGraduation\")) else x)\n",
    "train['Education Level'] = train['Education Level'].map(lambda x: 'EQF8' if ((x==\"PhD\")) else x)\n",
    "train[\"Education Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQNoWZ9sWB1q"
   },
   "source": [
    "### Profession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.556321Z",
     "start_time": "2020-12-12T11:18:01.542362Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_J04uF_WJYH",
    "outputId": "b3ebc3c1-94a6-4872-d684-d4d57f885d22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private Sector - Services     15599\n",
       "Self-Employed (Individual)     1764\n",
       "Public Sector - Others         1419\n",
       "nan                            1264\n",
       "Private Sector - Others         880\n",
       "Self-Employed (Company)         763\n",
       "Public Sector - Government      692\n",
       "Unemployed                       12\n",
       "Never Worked                      7\n",
       "Name: Employment Sector, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Employment Sector\"] = train[\"Employment Sector\"].astype(\"str\")\n",
    "train[\"Employment Sector\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.603194Z",
     "start_time": "2020-12-12T11:18:01.558315Z"
    },
    "id": "GmPNUgZvWauV"
   },
   "outputs": [],
   "source": [
    "train[\"Employment Sector\"]= train[\"Employment Sector\"].map(lambda x: 'Private Sector' if (\"Private Sector\" in x) else x)\n",
    "train[\"Employment Sector\"]= train[\"Employment Sector\"].map(lambda x: 'Public Sector' if (\"Public Sector\" in x) else x)\n",
    "train[\"Employment Sector\"]= train[\"Employment Sector\"].map(lambda x: 'Self Employed' if (\"Self-Employed\" in x) else x)\n",
    "train['Employment Sector'] = train['Employment Sector'].map(lambda x: 'Not Working' if ((x==\"Unemployed\") | (x== \"Never Worked\")) else x)\n",
    "train['Employment Sector'] = train['Employment Sector'].map(lambda x: np.nan if ((x==\"nan\")) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.618155Z",
     "start_time": "2020-12-12T11:18:01.605190Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sj2zwXNYvhV",
    "outputId": "a7933cb4-a279-48c0-c85b-32353f382490"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Private Sector    16479\n",
       "Self Employed      2527\n",
       "Public Sector      2111\n",
       "Not Working          19\n",
       "Name: Employment Sector, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Employment Sector\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r2WZxPUykwLN"
   },
   "source": [
    "### Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.634112Z",
     "start_time": "2020-12-12T11:18:01.620151Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVyAUhGrawdN",
    "outputId": "2f6030f6-9e80-4bf6-df85-cbf6f81f6625"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Professor                         2849\n",
       "Management                        2797\n",
       "Repair & constructions            2795\n",
       "Administratives                   2608\n",
       "Sales                             2531\n",
       "Other services                    2287\n",
       "Machine Operators & Inspectors    1384\n",
       "Transports                        1071\n",
       "Cleaners & Handlers                922\n",
       "Agriculture and Fishing            702\n",
       "IT                                 626\n",
       "Security                           450\n",
       "Household Services                 102\n",
       "Army                                 5\n",
       "Name: Role, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Role\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.650069Z",
     "start_time": "2020-12-12T11:18:01.636107Z"
    },
    "id": "YkNjLO_kl4Xw"
   },
   "source": [
    "1st Sector: Agriculture and Fishing <br> \n",
    "2nd Sector:Repair & constructions, Machine Operators & Inspectors <br>\n",
    "3rd Sector: Administratives, Sales, Other services, Transports, Cleaners & Handlers, Household Services, Security, Army <br> \n",
    "4th Sector: Quaternário: IT, Professor, Management <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.711904Z",
     "start_time": "2020-12-12T11:18:01.652064Z"
    },
    "id": "PCBvIb6QnaTd"
   },
   "outputs": [],
   "source": [
    "train[\"Role\"]= train[\"Role\"].map(lambda x: '1st Sector' if ((x==\"Agriculture and Fishing\")) else x)\n",
    "train[\"Role\"]= train[\"Role\"].map(lambda x: '2nd Sector' if ((x==\"Repair & constructions\") | (x== \"Machine Operators & Inspectors\"))else x)\n",
    "train[\"Role\"]= train[\"Role\"].map(lambda x: '3rd Sector' if ((x== \"Administratives\")| (x== \"Sales\")| (x== \"Other services\")| (x== \"Transports\")| (x== \"Cleaners & Handlers\")| (x== \"Household Services\")| (x== \"Security\")| (x== \"Army\"))else x)\n",
    "train[\"Role\"]= train[\"Role\"].map(lambda x: '4th Sector' if ((x==\"IT\") | (x== \"Professor\")| (x== \"Management\"))else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.727863Z",
     "start_time": "2020-12-12T11:18:01.713900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5pYP6o2nG-Q",
    "outputId": "f23bed56-f514-4d00-920d-7ab3512d6c93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3rd Sector    9976\n",
       "4th Sector    6272\n",
       "2nd Sector    4179\n",
       "1st Sector     702\n",
       "Name: Role, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Role\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy1Exjf7J-1w"
   },
   "source": [
    "### Ticket Price and Money"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "909g-y0QKQ6d"
   },
   "source": [
    "As for the description of the project, we have noticed that ticket price represents the information of how much someone payed to go to the planet, and, money received represents the money someone was payed to go to Newland. \n",
    "\n",
    "Given so, we consider that both variables represent the same thing but in different directions. We will then proceed to join both, adding the inverse sign to one of them (mudaria a descrição ligeiramente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.758779Z",
     "start_time": "2020-12-12T11:18:01.730856Z"
    }
   },
   "outputs": [],
   "source": [
    "train[\"MONEY_TICKET\"] = train[\"Money Received\"].map(lambda x: -x ) + train[\"Ticket Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.773741Z",
     "start_time": "2020-12-12T11:18:01.760774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Europe     19111\n",
       "Africa      2187\n",
       "Asia         699\n",
       "America      219\n",
       "Oceania      184\n",
       "Name: Native Continent, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"Native Continent\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Money Received and Ticket Price Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.805165Z",
     "start_time": "2020-12-12T11:18:01.775734Z"
    }
   },
   "outputs": [],
   "source": [
    "train['Money_Received_Binary'] = train['Money Received'].map(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "train['Ticket_Price_Binary'] = train['Ticket Price'].map(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "train['Money_Ticket_Binary'] = train['Money_Received_Binary'] + train['Ticket_Price_Binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuO-KYzHJST5"
   },
   "source": [
    "# **Missing Values Imputation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.836083Z",
     "start_time": "2020-12-12T11:18:01.807160Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhTB20wmuy3A",
    "outputId": "617f02db-04e7-4d00-c6c5-aa2ca5a021b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CITIZEN_ID                0.000000\n",
       "Native Continent          0.000000\n",
       "Marital Status            0.000000\n",
       "Lives with                0.000000\n",
       "Education Level           0.000000\n",
       "Years of Education        0.000000\n",
       "Employment Sector         5.642857\n",
       "Role                      5.674107\n",
       "Working Hours per week    0.000000\n",
       "Money Received            0.000000\n",
       "Ticket Price              0.000000\n",
       "Income                    0.000000\n",
       "Age                       0.000000\n",
       "Northbury                 0.000000\n",
       "Male                      0.000000\n",
       "MONEY_TICKET              0.000000\n",
       "Money_Received_Binary     0.000000\n",
       "Ticket_Price_Binary       0.000000\n",
       "Money_Ticket_Binary       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((train.isna().sum())/(train.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy dataframe\n",
    "mv_imputation = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"Encode\" the variables with missing values\n",
    "mv_imputation['Employment Sector'] = mv_imputation['Employment Sector'].map(lambda x: 0 if (x == 'Private Sector')\n",
    "                              else 1 if x == ('Public Sector')\n",
    "                              else 2 if x == ('Self Employed')\n",
    "                              else 3 if x == ('Not Working')\n",
    "                              else x)\n",
    "\n",
    "mv_imputation['Role'] = mv_imputation['Role'].map(lambda x: 0 if (x == '1st Sector')\n",
    "                              else 1 if x == ('2nd Sector')\n",
    "                              else 2 if x == ('3rd Sector')\n",
    "                              else 3 if x == ('4th Sector')\n",
    "                              else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training score for Employment Sector is : 0.7792760823278921\n",
      "The validation score for Employment Sector is : 0.7808397397989355\n",
      "With the mode the training set score would be  0.7796703729989748\n",
      "With the mode the validation set score would be  0.7796570076877587\n",
      "The training score for Role is : 0.5794746391101996\n",
      "The validation score for Role is : 0.5778513961192617\n",
      "With the mode the training set score would be  0.47219373668849096\n",
      "With the mode the validation set score would be  0.4720776147657359\n"
     ]
    }
   ],
   "source": [
    "#Split data between rows with and without missing values\n",
    "to_impute_ES = mv_imputation[mv_imputation['Employment Sector'].isna()].copy()\n",
    "to_train_ES = mv_imputation[~mv_imputation['Employment Sector'].isna()].copy()\n",
    "\n",
    "#Define independent variables\n",
    "independent_var = ['Years of Education', 'Working Hours per week', 'MONEY_TICKET', 'Age']\n",
    "\n",
    "#Split data\n",
    "MV_train, MV_val, ES_train, ES_val = train_test_split(to_train_ES[independent_var], to_train_ES['Employment Sector'], test_size = 0.40, stratify = to_train_ES['Employment Sector'], random_state = 15)\n",
    "\n",
    "#Standardize the data\n",
    "min_max_MV = MinMaxScaler().fit(MV_train)\n",
    "MV_train[MV_train.columns.to_list()] = min_max_MV.transform(MV_train)\n",
    "MV_val[MV_val.columns.to_list()] = min_max_MV.transform(MV_val) \n",
    "\n",
    "#Define and fit the model\n",
    "nn_ES = MLPClassifier(hidden_layer_sizes = (5,5), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 3).fit(MV_train,ES_train)\n",
    "\n",
    "#Print all the scores\n",
    "print('The training score for Employment Sector is :' ,nn_ES.score(MV_train,ES_train))\n",
    "print('The validation score for Employment Sector is :',nn_ES.score(MV_val,ES_val))\n",
    "print('With the mode the training set score would be ', (ES_train == to_train_ES[\"Employment Sector\"].mode()[0]).sum() / ES_train.shape[0])\n",
    "print('With the mode the validation set score would be ',(ES_val == to_train_ES[\"Employment Sector\"].mode()[0]).sum() / ES_val.shape[0])\n",
    "\n",
    "#Split data between rows with and without missing values\n",
    "to_impute_R = mv_imputation[mv_imputation['Role'].isna()].copy()\n",
    "to_train_R = mv_imputation[~mv_imputation['Role'].isna()].copy()\n",
    "\n",
    "#Split data\n",
    "MV_train, MV_val, R_train, R_val = train_test_split(to_train_R[independent_var], to_train_R['Role'], test_size = 0.40, stratify = to_train_R['Role'], random_state = 15)\n",
    "\n",
    "#Standardize the data\n",
    "min_max_MV = MinMaxScaler().fit(MV_train)\n",
    "MV_train[MV_train.columns.to_list()] = min_max_MV.transform(MV_train)\n",
    "MV_val[MV_val.columns.to_list()] = min_max_MV.transform(MV_val) \n",
    "\n",
    "#Define and fit the model\n",
    "nn_R = MLPClassifier(hidden_layer_sizes = (5,5), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 3).fit(MV_train,R_train)\n",
    "\n",
    "#Print all the scores\n",
    "print('The training score for Role is :' ,nn_R.score(MV_train,R_train))\n",
    "print('The validation score for Role is :',nn_R.score(MV_val,R_val))\n",
    "print('With the mode the training set score would be ', (R_train == to_train_R[\"Role\"].mode()[0]).sum() / R_train.shape[0])\n",
    "print('With the mode the validation set score would be ',(R_val == to_train_R[\"Role\"].mode()[0]).sum() / R_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Impute the missing values\n",
    "\n",
    "mv_imputation['Employment Sector'][mv_imputation['Employment Sector'].isna()] = nn_ES.predict(to_impute_ES[independent_var])\n",
    "mv_imputation['Role'][mv_imputation['Role'].isna()] = nn_R.predict(to_impute_R[independent_var])\n",
    "\n",
    "\n",
    "#Turn the values to their original categories\n",
    "mv_imputation['Employment Sector'] = mv_imputation['Employment Sector'].map(lambda x: 'Private Sector' if (x == 0)\n",
    "                              else 'Public Sector' if (x == 1)\n",
    "                              else 'Self Employed' if (x == 2)\n",
    "                              else 'Not Working' if (x == 3)\n",
    "                              else x)\n",
    "\n",
    "mv_imputation['Role'] = mv_imputation['Role'].map(lambda x: '1st Sector' if (x == 0)\n",
    "                              else '2nd Sector' if (x == 1)\n",
    "                              else '3rd Sector' if (x == 2)\n",
    "                              else '4th Sector' if (x == 3)\n",
    "                              else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quando quisermos usar esta imputation\n",
    "#Atenção que é preciso voltar a confirmar tudo das correlações e da feature selection\n",
    "#Por favor so usar isto dps de ja termos bue modelos feitos para podermos \"contar uma historia\" no report\n",
    "#No entanto duvido que melhore alguma coisa!!!\n",
    "\n",
    "#train = mv_imputation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.851042Z",
     "start_time": "2020-12-12T11:18:01.838077Z"
    },
    "id": "XZVgCTOs2Nex"
   },
   "outputs": [],
   "source": [
    "train[\"Employment Sector\"]= train[\"Employment Sector\"].fillna(train[\"Employment Sector\"].mode()[0])\n",
    "train[\"Role\"]= train[\"Role\"].fillna(train[\"Role\"].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.881963Z",
     "start_time": "2020-12-12T11:18:01.853037Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mb2reO5p26VJ",
    "outputId": "2a568c72-ecb8-4eba-de94-c92318eeb03c"
   },
   "outputs": [],
   "source": [
    "((train.isna().sum())/(train.shape[0])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awM3kIHXTLII"
   },
   "source": [
    "# **Data Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.896922Z",
     "start_time": "2020-12-12T11:18:01.883958Z"
    },
    "id": "28FyXTpT3gqC"
   },
   "outputs": [],
   "source": [
    "train_encoding = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.928840Z",
     "start_time": "2020-12-12T11:18:01.898919Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWSQkxDuzywW",
    "outputId": "d9b1eab1-ae4c-4c46-80d2-de0945b3c5f0"
   },
   "outputs": [],
   "source": [
    "print(\"Number of Categories in: \")\n",
    "for ColName in train[['Native Continent','Marital Status','Lives with', \"Employment Sector\",\"Role\"]]:\n",
    "    print(\"{} = {}\".format(ColName,len(train[ColName].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "Ntm96CXt3VJu"
   },
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:01.990677Z",
     "start_time": "2020-12-12T11:18:01.946791Z"
    },
    "hidden": true,
    "id": "h63WsnfJ3VJu"
   },
   "outputs": [],
   "source": [
    "one_hot_var = ohe(train_encoding, ['Native Continent', 'Marital Status', 'Lives with', \"Employment Sector\", \"Role\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.022591Z",
     "start_time": "2020-12-12T11:18:01.992673Z"
    },
    "hidden": true,
    "id": "Oo7fs4Xw3VJu"
   },
   "outputs": [],
   "source": [
    "train_encoding = pd.concat([train_encoding.drop(columns = ['Native Continent', 'Marital Status', 'Lives with', \"Employment Sector\", \"Role\"]), one_hot_var], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.037555Z",
     "start_time": "2020-12-12T11:18:02.026582Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "hidden": true,
    "id": "lssXIGb23VJu",
    "outputId": "171d8ab4-5740-4099-b572-9cb45607f2d7"
   },
   "outputs": [],
   "source": [
    "train_encoding.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "id": "1c_Y9Jdn3VJu"
   },
   "source": [
    "#### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.052513Z",
     "start_time": "2020-12-12T11:18:02.039547Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ecb0hSXh3rOP",
    "outputId": "49aa68c3-0c8c-45d6-c84b-009c5d4ea5ff"
   },
   "outputs": [],
   "source": [
    "train_encoding[\"Education Level\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.084427Z",
     "start_time": "2020-12-12T11:18:02.054519Z"
    },
    "hidden": true,
    "id": "8Vu0jfVz3VJu"
   },
   "outputs": [],
   "source": [
    "# create object of Ordinalencoding\n",
    "encoder= ce.OrdinalEncoder(cols=['Education Level'],return_df=True, mapping=[{'col':'Education Level','mapping':{'EQF3 or less':0,'EQF4':1,'EQF5':2,'EQF6':3,'EQF7':4,'EQF8':5}}])\n",
    "\n",
    "#fit and transform train data \n",
    "train_encoding = encoder.fit_transform(train_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.116354Z",
     "start_time": "2020-12-12T11:18:02.093402Z"
    },
    "id": "IjNhVYr1Q3HF"
   },
   "outputs": [],
   "source": [
    "train_encoding = train_encoding.rename(columns={\"Native Continent\": \"CONTINENT\", \"Lives with\": \"LIVES_WITH\", 'Education Level': \"EDUCATION_LVL\",\n",
    "                      'Years of Education': \"YEARS_EDUCATION\", 'Employment Sector': \"EMPLOY_SECTOR\", 'Role': \"ECON_SECTOR\",\n",
    "                      'Working Hours per week': \"WORKING_HOURS\", 'Income': \"INCOME\",'Marital Status': \"MARITAL_STATUS\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.131308Z",
     "start_time": "2020-12-12T11:18:02.119333Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train_encoding.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.146263Z",
     "start_time": "2020-12-12T11:18:02.134297Z"
    }
   },
   "outputs": [],
   "source": [
    "#######################Falta PCA\n",
    "#######################Mas acho que so devia ser feito dps de ja termos alguns modelos basicos\n",
    "#######################Em termos de report acho que não vale a pena termos logo um bom modelo, acho que faz muito mais\n",
    "#######################sentido fazermos primeiro tudo basico, fazer modelos e dps pensar em como os melhorar e ir \n",
    "#######################testando e melhorndo e anotando tudo para n perdermos nada no report\n",
    "#######################PLS N APAGUEM MESMO NADA QUE FIZERAM OU Q OS OUTROS FIZERAM SEM TODOS CONCORDAREM\n",
    "#######################BASTA POR EM COMENTARIO OU \"FAZER POR CIMA\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.162218Z",
     "start_time": "2020-12-12T11:18:02.148265Z"
    }
   },
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:02.193067Z",
     "start_time": "2020-12-12T11:18:02.166210Z"
    }
   },
   "outputs": [],
   "source": [
    "train_num = train[['YEARS_EDUCATION','WORKING_HOURS','Money Received','Ticket Price','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:05.959682Z",
     "start_time": "2020-12-12T11:18:02.198057Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_box_maker(train_num,'Outlier analysis',5,20,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_box_maker(train_num[['Money Received']][(train_num['Money Received'] != 0)],'Outlier analysis',1,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_box_maker(train_num[['Ticket Price']][(train['Ticket Price'] != 0)],'Outlier analysis',1,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:05.974660Z",
     "start_time": "2020-12-12T11:18:05.961644Z"
    }
   },
   "outputs": [],
   "source": [
    "filters_train = (\n",
    "                    (train['Age'] > 89) |\n",
    "                    (train['Money Received'] > 30000) |\n",
    "                    (train['Ticket Price'] > 4000) |\n",
    "                    (train['WORKING_HOURS'] > 95) |\n",
    "                    (train['YEARS_EDUCATION'] > 20)\n",
    "                                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:05.989567Z",
     "start_time": "2020-12-12T11:18:05.976605Z"
    }
   },
   "outputs": [],
   "source": [
    "#Dataframe with outliers\n",
    "\n",
    "train_out = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:06.020518Z",
     "start_time": "2020-12-12T11:18:05.991565Z"
    }
   },
   "outputs": [],
   "source": [
    "train[(~(filters_train))].shape[0] /train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:06.036499Z",
     "start_time": "2020-12-12T11:18:06.022480Z"
    }
   },
   "outputs": [],
   "source": [
    "train=train[(~(filters_train))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filter methods**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corr=train[train_num.columns.to_list()].corr(method = \"pearson\")\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(data = train_corr, annot = True, cmap=sns.diverging_palette(220, 10, as_cmap=True), fmt='.2',  vmin=-1, vmax=1, center=0,square=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:23.658470Z",
     "start_time": "2020-12-12T11:18:06.102267Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J81NDFYaJbS6",
    "outputId": "3721d5bd-dcc0-464f-fa4f-c103c8815d16",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_corr=train.corr(method = \"spearman\")\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(data = train_corr, annot = True, cmap=sns.diverging_palette(220, 10, as_cmap=True), fmt='.2',  vmin=-1, vmax=1, center=0,square=True )\n",
    "\n",
    "#Acho que tmb devíamos fazer aquela matriz de scatter plots e histogramas, o que iria substituir os histogramas em cima\n",
    "#e teríamos de fazer os boxplots na mesma\n",
    "\n",
    "#Não esquecer que para comparar binárias, se n me engano, uma matriz espécie TP, TN tmb era fixe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:23.689414Z",
     "start_time": "2020-12-12T11:18:23.664439Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop(columns =[\"EDUCATION_LVL\", \"x1_Married\", \"CITIZEN_ID\", \"x0_Africa\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = train.drop(columns = ['YEARS_EDUCATION', 'WORKING_HOURS', 'Money Received', 'Ticket Price', 'Age', 'INCOME','MONEY_TICKET']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://heartbeat.fritz.ai/hands-on-with-feature-selection-techniques-filter-methods-f248e0436ce5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_score, chi_2_p_value = chi2(train[binary], train['INCOME'])\n",
    "f_score, f_p_value = f_classif(train[train.drop(columns=binary).columns.to_list()],train['INCOME'])\n",
    "print('Binary Columns: ', train[binary].columns)\n",
    "print('Metric Columns: ', train.drop(columns=binary).columns)\n",
    "print('chi2 score        ', chi2_score)\n",
    "print('chi2 p-value      ', chi_2_p_value)\n",
    "print('F - score score   ', f_score)\n",
    "print('F - score p-value ', f_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables to drop due to chi-squared\n",
    "train.drop(columns =[\"Northbury\", 'x0_Asia', 'x3_Not Working'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:23.704380Z",
     "start_time": "2020-12-12T11:18:23.691413Z"
    }
   },
   "outputs": [],
   "source": [
    "#variables to drop due to multicoliniarity\n",
    "train.drop(columns =['x2_Alone', 'x4_3rd Sector'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:23.796129Z",
     "start_time": "2020-12-12T11:18:23.788152Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.drop(columns = ['INCOME'])\n",
    "y = train['INCOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:23.855977Z",
     "start_time": "2020-12-12T11:18:23.801140Z"
    },
    "id": "wtJ-Xll0S9Mw"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.40, stratify = y, random_state = 15)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size = 0.50, stratify = y_val, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:24.025887Z",
     "start_time": "2020-12-12T11:18:23.893875Z"
    }
   },
   "outputs": [],
   "source": [
    "min_max = MinMaxScaler().fit(X_train)\n",
    "X_train[X_train.columns.to_list()] = min_max.transform(X_train)\n",
    "X_val[X_val.columns.to_list()] = min_max.transform(X_val) \n",
    "X_test[X_test.columns.to_list()] = min_max.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:24.070793Z",
     "start_time": "2020-12-12T11:18:24.027882Z"
    }
   },
   "outputs": [],
   "source": [
    "#Df's to be used\n",
    "\n",
    "X_train_Original = X_train.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "X_val_Original = X_val.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "X_test_Original = X_test.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_MTB = X_train.drop(columns = ['Money Received', 'Ticket Price', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "X_val_MTB = X_val.drop(columns = ['Money Received', 'Ticket Price', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "X_test_MTB = X_test.drop(columns = ['Money Received', 'Ticket Price', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_MT = X_train.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary','Money Received', 'Ticket Price', 'MONEY_TICKET'])\n",
    "X_val_MT = X_val.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary','Money Received', 'Ticket Price', 'MONEY_TICKET'])\n",
    "X_test_MT = X_test.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary','Money Received', 'Ticket Price', 'MONEY_TICKET'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkOUssp0suxv"
   },
   "source": [
    "# **Feature Selection**\n",
    "\n",
    "Não esquecer que devemos especificar um random state para cada função/algoritmo para ter resultados consistentes.\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/tutorials/model.html\n",
    "https://www.datacamp.com/community/tutorials/xgboost-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"feature_selection2..png\" alt=\"feature_selection_logic\" width=\"700\" height=\"700\"  align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/feature-selection-techniques-for-classification-and-python-tips-for-their-application-10c0ddd7918b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:24.085727Z",
     "start_time": "2020-12-12T11:18:24.073759Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_original = X_train_Original.drop(columns = ['YEARS_EDUCATION', 'WORKING_HOURS', 'Money Received', 'Ticket Price', 'Age']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# não mexam nisto tenho quase a certeza absoluta que funciona e que e assim que se faz mas vou pesquizar melhor\n",
    "fs = SelectKBest(score_func=chi2, k='all')\n",
    "fs.fit(X_train_Original[binary_original], y_train)\n",
    "X_train_fs = fs.transform(X_train_Original[binary_original])\n",
    "names=list(X_train_Original[binary_original].columns)\n",
    "print(fs)\n",
    "\n",
    "df_scores_chi2 = pd.DataFrame(list(zip(names, fs.scores_)), columns =['Variable', 'Score']).sort_values(by = [\"Score\"], ascending = False)\n",
    "print(df_scores_chi2)\n",
    "\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Wrapper method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/10/a-comprehensive-guide-to-feature-selection-using-wrapper-methods-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "################Qnd decidirmos se utilizamos isto passar os imports pa cima################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "#Pq n o RFECV\n",
    "\n",
    "#Acho que deviamos acrescentar tmb repeated stratifiedkfold aqui, como mostra o link em baixo\n",
    "#https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
    "\n",
    "# nro of features\n",
    "nof_list=np.arange(1,22)            \n",
    "high_score=0\n",
    "# Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "\n",
    "    X_train_rfe, X_rfe_val, y_train_rfe, y_rfe_val = train_test_split(X_train_Original[binary_original], y_train, test_size = 0.2, stratify = y_train,\n",
    "                                                                      random_state = 15)\n",
    "    \n",
    "    model_rfe = LogisticRegression(random_state = 5)\n",
    "    rfe = RFE(model_rfe,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train_rfe,y_train_rfe)\n",
    "    X_rfe_val = rfe.transform(X_rfe_val)\n",
    "    \n",
    "    model_rfe.fit(X_train_rfe,y_train_rfe)\n",
    "    \n",
    "    score = model_rfe.score(X_rfe_val,y_rfe_val)\n",
    "    score_list.append(score)\n",
    "    \n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "        \n",
    "\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "model_rfe = LogisticRegression(random_state = 5)\n",
    "rfe = RFE(estimator = model_rfe, n_features_to_select = N)\n",
    "X_rfe = rfe.fit_transform(X = X_train_Original[binary_original], y = y_train) \n",
    "\n",
    "selected_features_rfe = pd.Series(rfe.ranking_, index = X_train_Original[binary_original].columns)\n",
    "selected_features_rfe.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################Qnd decidirmos se utilizamos isto passar os imports pa cima################\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "#Pq n o RFECV\n",
    "\n",
    "#Acho que deviamos acrescentar tmb repeated stratifiedkfold aqui, como mostra o link em baixo\n",
    "#https://machinelearningmastery.com/rfe-feature-selection-in-python/\n",
    "\n",
    "# nro of features\n",
    "nof_list=np.arange(1,22)            \n",
    "high_score=0\n",
    "# Variable to store the optimum features\n",
    "nof=0           \n",
    "score_list =[]\n",
    "for n in range(len(nof_list)):\n",
    "\n",
    "    X_train_rfe, X_rfe_val, y_train_rfe, y_rfe_val = train_test_split(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train, test_size = 0.2, stratify = y_train,\n",
    "                                                                      random_state = 15)\n",
    "    \n",
    "    model_rfe = DecisionTreeClassifier(random_state = 5)\n",
    "    rfe = RFE(model_rfe,nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train_rfe,y_train_rfe)\n",
    "    X_rfe_val = rfe.transform(X_rfe_val)\n",
    "    \n",
    "    model_rfe.fit(X_train_rfe,y_train_rfe)\n",
    "    \n",
    "    score = model_rfe.score(X_rfe_val,y_rfe_val)\n",
    "    score_list.append(score)\n",
    "    \n",
    "    if(score>high_score):\n",
    "        high_score = score\n",
    "        nof = nof_list[n]\n",
    "        \n",
    "\n",
    "print(\"Optimum number of features: %d\" %nof)\n",
    "print(\"Score with %d features: %f\" % (nof, high_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "model_rfe = DecisionTreeClassifier(random_state = 5)\n",
    "rfe = RFE(estimator = model_rfe, n_features_to_select = N)\n",
    "X_rfe = rfe.fit_transform(X = X_train_Original.drop(columns=X_train_Original[binary_original]), y = y_train) \n",
    "\n",
    "selected_features_rfe = pd.Series(rfe.ranking_, index = X_train_Original.drop(columns=X_train_Original[binary_original]).columns)\n",
    "selected_features_rfe.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "model_rfe = LogisticRegression(random_state = 5)\n",
    "rfe = RFE(estimator = model_rfe, n_features_to_select = N)\n",
    "X_rfe = rfe.fit_transform(X = X_train_Original.drop(columns=X_train_Original[binary_original]), y = y_train) \n",
    "\n",
    "selected_features_rfe = pd.Series(rfe.ranking_, index = X_train_Original.drop(columns=X_train_Original[binary_original]).columns)\n",
    "selected_features_rfe.sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Intrinsic Methods**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier - gini and entropy - binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:24.146160Z",
     "start_time": "2020-12-12T11:18:24.088720Z"
    }
   },
   "outputs": [],
   "source": [
    "gini_importance = DecisionTreeClassifier().fit(X_train_Original[binary_original], y_train).feature_importances_\n",
    "entropy_importance = DecisionTreeClassifier(criterion='entropy').fit(X_train_Original[binary_original], y_train).feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:18:25.078034Z",
     "start_time": "2020-12-12T11:18:24.154060Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zippy = pd.DataFrame(zip(gini_importance, entropy_importance), columns = ['gini','entropy'])\n",
    "zippy['col'] = X_train_Original[binary_original].columns\n",
    "tidy = zippy.melt(id_vars='col').rename(columns=str.title)\n",
    "tidy.sort_values(['Value'], ascending = False, inplace = True)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(y='Col', x='Value', hue='Variable', data=tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier - gini and entropy - numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_importance = DecisionTreeClassifier().fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train).feature_importances_\n",
    "entropy_importance = DecisionTreeClassifier(criterion='entropy').fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train).feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zippy = pd.DataFrame(zip(gini_importance, entropy_importance), columns = ['gini','entropy'])\n",
    "zippy['col'] = X_train_Original.drop(columns=X_train_Original[binary_original]).columns\n",
    "tidy = zippy.melt(id_vars='col').rename(columns=str.title)\n",
    "tidy.sort_values(['Value'], ascending = False, inplace = True)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(y='Col', x='Value', hue='Variable', data=tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier - gini and entropy - binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:36:50.861575Z",
     "start_time": "2020-12-12T11:36:48.726229Z"
    }
   },
   "outputs": [],
   "source": [
    "gini_importanceRF = RandomForestClassifier().fit(X_train_Original[binary_original], y_train).feature_importances_\n",
    "entropy_importanceRF = RandomForestClassifier(criterion='entropy').fit(X_train_Original[binary_original], y_train).feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:36:52.434051Z",
     "start_time": "2020-12-12T11:36:51.775027Z"
    }
   },
   "outputs": [],
   "source": [
    "zippy = pd.DataFrame(zip(gini_importanceRF, entropy_importanceRF), columns = ['gini','entropy'])\n",
    "zippy['col'] = X_train_Original[binary_original].columns\n",
    "tidy = zippy.melt(id_vars='col').rename(columns=str.title)\n",
    "tidy.sort_values(['Value'], ascending = False, inplace = True)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(y='Col', x='Value', hue='Variable', data=tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier - gini and entropy - numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_importanceRF = RandomForestClassifier().fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train).feature_importances_\n",
    "entropy_importanceRF = RandomForestClassifier(criterion='entropy').fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train).feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zippy = pd.DataFrame(zip(gini_importanceRF, entropy_importanceRF), columns = ['gini','entropy'])\n",
    "zippy['col'] = X_train_Original.drop(columns=X_train_Original[binary_original]).columns\n",
    "tidy = zippy.melt(id_vars='col').rename(columns=str.title)\n",
    "tidy.sort_values(['Value'], ascending = False, inplace = True)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "sns.barplot(y='Col', x='Value', hue='Variable', data=tidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Embbeded Methods**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso - numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:21:41.553269Z",
     "start_time": "2020-12-12T11:21:41.122448Z"
    },
    "id": "L2CDVoIOXcFP"
   },
   "outputs": [],
   "source": [
    "#Feature selction trough Lasso\n",
    "Lasso_Best_Alpha = LassoCV(cv = 10, random_state = 2)\n",
    "Lasso_Best_Alpha = Lasso_Best_Alpha.fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:21:41.568230Z",
     "start_time": "2020-12-12T11:21:41.556262Z"
    }
   },
   "outputs": [],
   "source": [
    "Lasso_Best_Alpha.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:21:42.108859Z",
     "start_time": "2020-12-12T11:21:41.571222Z"
    }
   },
   "outputs": [],
   "source": [
    "Lasso_Reg = Lasso(alpha = Lasso_Best_Alpha.alpha_, random_state = 2)\n",
    "Lasso_Reg.fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train)\n",
    "coef_Lasso = pd.Series(Lasso_Reg.coef_, index = X_train_Original.drop(columns=X_train_Original[binary_original]).columns)\n",
    "coef_Lasso.sort_values()\n",
    "plot_importance(coef_Lasso, 'Lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso - binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selction trough Lasso\n",
    "Lasso_Best_Alpha = LassoCV(cv = 10, random_state = 2)\n",
    "Lasso_Best_Alpha = Lasso_Best_Alpha.fit(X_train_Original[binary_original], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_Best_Alpha.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_Reg = Lasso(alpha = Lasso_Best_Alpha.alpha_, random_state = 2)\n",
    "Lasso_Reg.fit(X_train_Original[binary_original], y_train)\n",
    "coef_Lasso = pd.Series(Lasso_Reg.coef_, index = X_train_Original[binary_original].columns)\n",
    "coef_Lasso.sort_values()\n",
    "plot_importance(coef_Lasso, 'Lasso')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge - numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:21:59.790051Z",
     "start_time": "2020-12-12T11:21:42.110798Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_alphas = np.linspace(0.1,100, num= 100)\n",
    "Ridge_Best_Alpha = RidgeClassifierCV(alphas = ridge_alphas, cv = 10)\n",
    "Ridge_Best_Alpha = Ridge_Best_Alpha.fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train)\n",
    "\n",
    "print('Best alpha for Ridge:', Ridge_Best_Alpha.alpha_)\n",
    "Ridge = RidgeClassifier(alpha = Ridge_Best_Alpha.alpha_, random_state = 2)\n",
    "Ridge = Ridge.fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train)\n",
    "\n",
    "coef_Ridge = pd.Series(Ridge.coef_[0], index = X_train_Original.drop(columns=X_train_Original[binary_original]).columns)\n",
    "coef_Ridge.sort_values()\n",
    "plot_importance(coef_Ridge, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge - binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge_alphas = np.linspace(0.1,100, num= 100)\n",
    "Ridge_Best_Alpha = RidgeClassifierCV(alphas = ridge_alphas, cv = 10)\n",
    "Ridge_Best_Alpha = Ridge_Best_Alpha.fit(X_train_Original[binary_original], y_train)\n",
    "\n",
    "print('Best alpha for Ridge:', Ridge_Best_Alpha.alpha_)\n",
    "Ridge = RidgeClassifier(alpha = Ridge_Best_Alpha.alpha_, random_state = 2)\n",
    "Ridge = Ridge.fit(X_train_Original[binary_original], y_train)\n",
    "\n",
    "coef_Ridge = pd.Series(Ridge.coef_[0], index = X_train_Original[binary_original].columns)\n",
    "coef_Ridge.sort_values()\n",
    "plot_importance(coef_Ridge, 'Ridge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net - numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:02.619319Z",
     "start_time": "2020-12-12T11:21:59.791719Z"
    }
   },
   "outputs": [],
   "source": [
    "ElasticNet_Best_L1_Alpha = ElasticNetCV(l1_ratio = [.1, .5, .7, .9, .95, .99, 1], cv = 10, random_state = 2) \n",
    "ElasticNet_Best_L1_Alpha = ElasticNet_Best_L1_Alpha.fit(X_train_Original, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:02.634336Z",
     "start_time": "2020-12-12T11:22:02.622310Z"
    }
   },
   "outputs": [],
   "source": [
    "print(ElasticNet_Best_L1_Alpha.l1_ratio_) #Best l1\n",
    "print(ElasticNet_Best_L1_Alpha.alpha_)#Best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:03.163840Z",
     "start_time": "2020-12-12T11:22:02.640418Z"
    }
   },
   "outputs": [],
   "source": [
    "ElasticNet_Reg = ElasticNet(l1_ratio = ElasticNet_Best_L1_Alpha.l1_ratio_, alpha = ElasticNet_Best_L1_Alpha.alpha_, random_state = 2)\n",
    "ElasticNet_Reg.fit(X_train_Original.drop(columns=X_train_Original[binary_original]), y_train)\n",
    "coef_ElasticNet = pd.Series(ElasticNet_Reg.coef_, index = X_train_Original.drop(columns=X_train_Original[binary_original]).columns)\n",
    "coef_ElasticNet.sort_values()\n",
    "plot_importance(coef_ElasticNet, 'ElasticNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net - binary variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticNet_Best_L1_Alpha = ElasticNetCV(l1_ratio = [0.0001,.1, .5, .7, .9, .95, .99, 1], cv = 10, random_state = 2) \n",
    "ElasticNet_Best_L1_Alpha = ElasticNet_Best_L1_Alpha.fit(X_train_Original[binary_original], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ElasticNet_Best_L1_Alpha.l1_ratio_) #Best l1\n",
    "print(ElasticNet_Best_L1_Alpha.alpha_)#Best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ElasticNet_Reg = ElasticNet(l1_ratio = ElasticNet_Best_L1_Alpha.l1_ratio_, alpha = ElasticNet_Best_L1_Alpha.alpha_, random_state = 2)\n",
    "ElasticNet_Reg.fit(X_train_Original[binary_original], y_train)\n",
    "coef_ElasticNet = pd.Series(ElasticNet_Reg.coef_, index = X_train_Original[binary_original].columns)\n",
    "coef_ElasticNet.sort_values()\n",
    "plot_importance(coef_ElasticNet, 'ElasticNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHuluPEPsyD2"
   },
   "source": [
    "# **Artificial Resampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_AR = X_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RO = RandomOverSampler(sampling_strategy='minority', random_state=15)\n",
    "X_RO, y_RO = RO.fit_resample(X_train_AR, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_RO_Original = X_RO.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_RO_MTB = X_RO.drop(columns = ['Money Received', 'Ticket Price', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_RO_MT = X_RO.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary','Money Received', 'Ticket Price', 'MONEY_TICKET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Minority Oversampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMOTE = SMOTE(sampling_strategy='minority', random_state=15)\n",
    "X_SMOTE, y_SMOTE = SMOTE.fit_resample(X_train_AR, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SMOTE_Original = X_SMOTE.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_SMOTE_MTB = X_SMOTE.drop(columns = ['Money Received', 'Ticket Price', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_SMOTE_MT = X_SMOTE.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary','Money Received', 'Ticket Price', 'MONEY_TICKET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Synthetic Oversampling (ADASYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADASYN = ADASYN(sampling_strategy='minority', random_state=15)\n",
    "X_ADASYN, y_ADASYN = ADASYN.fit_resample(X_train_AR, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ADASYN_Original = X_ADASYN.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_ADASYN_MTB = X_ADASYN.drop(columns = ['Money Received', 'Ticket Price', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_ADASYN_MT = X_ADASYN.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary','Money Received', 'Ticket Price', 'MONEY_TICKET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster-Based Undersampling (K-Means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CBU = ClusterCentroids(sampling_strategy='majority', random_state=15)\n",
    "X_CBU, y_CBU = CBU.fit_resample(X_train_AR, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_CBU_Original = X_CBU.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_CBU_MTB = X_CBU.drop(columns = ['Money Received', 'Ticket Price', \"MONEY_TICKET\", 'Money_Ticket_Binary'])\n",
    "\n",
    "X_train_CBU_MT = X_CBU.drop(columns = ['Money_Received_Binary', 'Ticket_Price_Binary','Money Received', 'Ticket Price', 'MONEY_TICKET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oBwQQS2s1UQ"
   },
   "source": [
    "# **Model Exploration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.354075Z",
     "start_time": "2020-12-12T11:22:18.325151Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_FirstTry = X_train_Original.drop(columns = ['x0_Oceania', 'x0_America', 'x1_Not Married', 'x3_Private Sector', 'x4_2nd Sector'])\n",
    "\n",
    "X_train_MTB_FirstTry = X_train_MTB.drop(columns = ['x0_Oceania', 'x0_America', 'x1_Not Married', 'x3_Private Sector', 'x4_2nd Sector'])\n",
    "\n",
    "X_train_SecondTry = X_train_Original[['Money Received', 'YEARS_EDUCATION', 'Ticket Price', 'WORKING_HOURS', 'Age', 'x4_4th Sector', 'x2_Spouse', 'x4_1st Sector', 'x2_Children', 'x2_Other Family', 'Male', 'x3_Private Sector']]\n",
    "\n",
    "X_train_MT_SecondTry = X_train_MT[['Money_Ticket_Binary', 'YEARS_EDUCATION', 'WORKING_HOURS', 'Age', 'x4_4th Sector', 'x2_Spouse', 'x4_1st Sector', 'x2_Children', 'x2_Other Family', 'Male', 'x3_Private Sector']]\n",
    "\n",
    "X_train_ThirdTry = X_train_Original[['Money Received', 'YEARS_EDUCATION', 'Ticket Price', 'WORKING_HOURS', 'x4_4th Sector', 'x2_Spouse']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.385988Z",
     "start_time": "2020-12-12T11:22:18.357068Z"
    }
   },
   "outputs": [],
   "source": [
    "X_val_FirstTry = X_val_Original[X_train_FirstTry.columns.to_list()]\n",
    "\n",
    "X_val_MTB_FirstTry = X_val_MTB[X_train_MTB_FirstTry.columns.to_list()]\n",
    "\n",
    "X_val_SecondTry = X_val_Original[X_train_SecondTry.columns.to_list()]\n",
    "\n",
    "X_val_MT_SecondTry = X_val_MT[X_train_MT_SecondTry.columns.to_list()]\n",
    "\n",
    "X_val_ThirdTry = X_val_Original[X_train_ThirdTry.columns.to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.401946Z",
     "start_time": "2020-12-12T11:22:18.388982Z"
    }
   },
   "outputs": [],
   "source": [
    "######Test final!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.417903Z",
     "start_time": "2020-12-12T11:22:18.404939Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.432864Z",
     "start_time": "2020-12-12T11:22:18.420896Z"
    }
   },
   "outputs": [],
   "source": [
    "#parameter_space = {\n",
    "#    'hidden_layer_sizes': [(5), (6), (7), (8), (9), (10), (11), (12), (13), (14), (5,5), (6,6), (7,7), (8,8), (9,9), (10,10), (11,11), (12,12), (13,13), (14,14)],\n",
    "#    'activation': ['tanh', 'relu', 'logistic'],\n",
    "#    'solver': ['sgd', 'adam'],\n",
    "#    'learning_rate_init': list(np.linspace(0.00001,0.1,5)),\n",
    "#    'learning_rate': ['constant','adaptive']\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.447824Z",
     "start_time": "2020-12-12T11:22:18.435856Z"
    }
   },
   "outputs": [],
   "source": [
    "#First_GS = GridSearchCV(model, parameter_space, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.463780Z",
     "start_time": "2020-12-12T11:22:18.450816Z"
    }
   },
   "outputs": [],
   "source": [
    "#First_GS.fit(X_train_FirstTry, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.478745Z",
     "start_time": "2020-12-12T11:22:18.466774Z"
    }
   },
   "outputs": [],
   "source": [
    "#First_GS.best_params_\n",
    "\n",
    "#{'activation': 'tanh',\n",
    "# 'hidden_layer_sizes': 9,\n",
    "# 'learning_rate': 'constant',\n",
    "# 'learning_rate_init': 0.025007500000000002,\n",
    "# 'solver': 'adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.493702Z",
     "start_time": "2020-12-12T11:22:18.488716Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Best parameter set\n",
    "#print('------------------------------------------------------------------------------------------------------------------------')\n",
    "#print('Best parameters found:\\n', First_GS.best_params_)\n",
    "#print('------------------------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "# All results\n",
    "#means = First_GS.cv_results_['mean_test_score']\n",
    "#stds = First_GS.cv_results_['std_test_score']\n",
    "#for mean, std, params in zip(means, stds, First_GS.cv_results_['params']):\n",
    "#    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std , params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:18.508660Z",
     "start_time": "2020-12-12T11:22:18.500684Z"
    }
   },
   "outputs": [],
   "source": [
    "First_NN = MLPClassifier(hidden_layer_sizes = (9), activation = 'tanh', learning_rate = 'constant', solver = 'adam', learning_rate_init = 0.025007500000000002, max_iter = 1000, random_state = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:20.068689Z",
     "start_time": "2020-12-12T11:22:18.512651Z"
    }
   },
   "outputs": [],
   "source": [
    "First_NN.fit(X_train_FirstTry, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:20.132484Z",
     "start_time": "2020-12-12T11:22:20.070685Z"
    }
   },
   "outputs": [],
   "source": [
    "metrics(y_train, First_NN.predict(X_train_FirstTry), y_val, First_NN.predict(X_val_FirstTry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:20.148438Z",
     "start_time": "2020-12-12T11:22:20.134479Z"
    }
   },
   "outputs": [],
   "source": [
    "Second_NN = MLPClassifier(hidden_layer_sizes = (9), activation = 'tanh', solver = 'adam', learning_rate_init = 0.025007500000000002, max_iter = 1000, random_state = 15, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:22.501506Z",
     "start_time": "2020-12-12T11:22:20.150434Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Second_NN.fit(X_train_SecondTry, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:22.533350Z",
     "start_time": "2020-12-12T11:22:22.503430Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:22.549340Z",
     "start_time": "2020-12-12T11:22:22.536341Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:22.564266Z",
     "start_time": "2020-12-12T11:22:22.551302Z"
    }
   },
   "outputs": [],
   "source": [
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (12,12), activation = 'tanh', solver = 'sgd', learning_rate = 'adaptive', learning_rate_init = 0.02, max_iter = 1000, random_state = 15, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:22.579359Z",
     "start_time": "2020-12-12T11:22:22.566267Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Second_NN.fit(X_train_SecondTry, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:22.595316Z",
     "start_time": "2020-12-12T11:22:22.581353Z"
    }
   },
   "outputs": [],
   "source": [
    "#metrics(y_train, Second_NN.predict(X_train_SecondTry), y_val, Second_NN.predict(X_val_SecondTry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:22.610274Z",
     "start_time": "2020-12-12T11:22:22.598307Z"
    }
   },
   "outputs": [],
   "source": [
    "Second_NN = MLPClassifier(hidden_layer_sizes = (9), activation = 'tanh', solver = 'adam', learning_rate_init = 0.025007500000000002, max_iter = 1000, batch_size = X_train_SecondTry.shape[0], random_state = 15, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:24.579169Z",
     "start_time": "2020-12-12T11:22:22.612270Z"
    }
   },
   "outputs": [],
   "source": [
    "Second_NN.fit(X_train_SecondTry, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:24.610108Z",
     "start_time": "2020-12-12T11:22:24.582161Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:24.640027Z",
     "start_time": "2020-12-12T11:22:24.614103Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:24.654989Z",
     "start_time": "2020-12-12T11:22:24.643020Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_SecondTry.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:24.669947Z",
     "start_time": "2020-12-12T11:22:24.658978Z"
    }
   },
   "outputs": [],
   "source": [
    "Second_NN = MLPClassifier(hidden_layer_sizes = (12,20), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, batch_size=50, random_state = 15, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:44.778900Z",
     "start_time": "2020-12-12T11:22:24.671944Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Second_NN.fit(X_train_SecondTry, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:44.839827Z",
     "start_time": "2020-12-12T11:22:44.785883Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:44.886665Z",
     "start_time": "2020-12-12T11:22:44.841785Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))\n",
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (12,20), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, batch_size=50, random_state = 15, verbose = 10)\n",
    "#0.8573660714285715\n",
    "#0.8591517857142857\n",
    "#With Married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:44.934537Z",
     "start_time": "2020-12-12T11:22:44.889659Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))\n",
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (12,20), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.000001, random_state = 15, verbose = 10)\n",
    "#0.8574404761904761\n",
    "#0.8569196428571428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:44.980449Z",
     "start_time": "2020-12-12T11:22:44.936561Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))\n",
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (10,20), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 15, verbose = 10)\n",
    "#0.8557291666666667\n",
    "#0.8522321428571429"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:45.026291Z",
     "start_time": "2020-12-12T11:22:44.982409Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))\n",
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (12,20), activation = 'relu', solver = 'sgd', learning_rate = 'adaptive', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 15, verbose = 10)\n",
    "#0.853125\n",
    "#0.8511160714285713"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:45.072206Z",
     "start_time": "2020-12-12T11:22:45.028288Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))\n",
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (12,20), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 15, verbose = 10)\n",
    "#0.8587797619047618\n",
    "#0.85625"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:45.118049Z",
     "start_time": "2020-12-12T11:22:45.074165Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))\n",
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (20,20), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 15, verbose = 10)\n",
    "#0.8608630952380952\n",
    "#0.8551339285714286"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:45.163963Z",
     "start_time": "2020-12-12T11:22:45.120041Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))\n",
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (20,50), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 15, verbose = 10)\n",
    "#0.8644345238095239\n",
    "#0.8560267857142857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:45.208805Z",
     "start_time": "2020-12-12T11:22:45.165921Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Second_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Second_NN.predict(X_val_SecondTry), average = 'micro'))\n",
    "#Second_NN = MLPClassifier(hidden_layer_sizes = (50,100), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 15, verbose = 10)\n",
    "#0.8656994047619048\n",
    "#0.8513392857142857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:45.223802Z",
     "start_time": "2020-12-12T11:22:45.210800Z"
    }
   },
   "outputs": [],
   "source": [
    "Third_NN = MLPClassifier(hidden_layer_sizes = (35,80), activation = 'relu', solver = 'adam', learning_rate_init = 0.01, max_iter = 1000,  alpha=0.00001, random_state = 14, verbose = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.500458Z",
     "start_time": "2020-12-12T11:22:45.225760Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Third_NN.fit(X_train_SecondTry, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.637095Z",
     "start_time": "2020-12-12T11:22:57.503450Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_train, Third_NN.predict(X_train_SecondTry), average = 'micro'))\n",
    "print(f1_score(y_val, Third_NN.predict(X_val_SecondTry), average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pessoal cuidado eu fui parvo e e aqui eu vou sobreporo o X_train_original pelo com as variaveis escolhidas pq me esqueci de fazer isto antes\n",
    "por isso se correrem este codigo não se esqueçam disto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.700440Z",
     "start_time": "2020-12-12T11:22:57.672515Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tree=X_train_Original.drop(columns=[\n",
    "        'Northbury', 'Male', 'x0_America', 'x0_Asia', 'x0_Europe',\n",
    "       'x0_Oceania',  'x1_Not Married',  \n",
    "        'x3_Not Working', 'x3_Private Sector',\n",
    "       'x3_Public Sector', 'x4_1st Sector', 'x4_2nd Sector'])\n",
    "\n",
    "X_test_tree=X_test_Original.drop(columns=[\n",
    "        'Northbury', 'Male', 'x0_America', 'x0_Asia', 'x0_Europe',\n",
    "       'x0_Oceania',  'x1_Not Married',  \n",
    "        'x3_Not Working', 'x3_Private Sector',\n",
    "       'x3_Public Sector', 'x4_1st Sector', 'x4_2nd Sector'])\n",
    "X_val_Original_tree=X_val_Original.drop(columns=[\n",
    "        'Northbury', 'Male', 'x0_America', 'x0_Asia', 'x0_Europe',\n",
    "       'x0_Oceania',  'x1_Not Married',  \n",
    "        'x3_Not Working', 'x3_Private Sector',\n",
    "       'x3_Public Sector', 'x4_1st Sector', 'x4_2nd Sector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.716399Z",
     "start_time": "2020-12-12T11:22:57.704430Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.731358Z",
     "start_time": "2020-12-12T11:22:57.723379Z"
    }
   },
   "outputs": [],
   "source": [
    "X = X_val_Original_tree\n",
    "y = y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.761847Z",
     "start_time": "2020-12-12T11:22:57.734350Z"
    }
   },
   "outputs": [],
   "source": [
    "def avg_score(model):\n",
    "    # apply kfold\n",
    "    kf = KFold(n_splits=10)\n",
    "    # create lists to store the results from the different models \n",
    "    score_train = []\n",
    "    score_test = []\n",
    "    timer = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        # get the indexes of the observations assigned for each partition\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # start counting time\n",
    "        begin = time.perf_counter()\n",
    "        # fit the model to the data\n",
    "        model.fit(X_train, y_train)\n",
    "        # finish counting time\n",
    "        end = time.perf_counter()\n",
    "        # check the mean accuracy for the train\n",
    "        value_train = model.score(X_train, y_train)\n",
    "        # check the mean accuracy for the test\n",
    "        value_test = model.score(X_test,y_test)\n",
    "        # append the accuracies, the time and the number of iterations in the corresponding list\n",
    "        score_train.append(value_train)\n",
    "        score_test.append(value_test)\n",
    "        timer.append(end-begin)\n",
    "    # calculate the average and the std for each measure (accuracy, time and number of iterations)\n",
    "    avg_time = round(np.mean(timer),3)\n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_test = round(np.mean(score_test),3)\n",
    "    std_time = round(np.std(timer),2)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_test = round(np.std(score_test),2)\n",
    "    \n",
    "    return str(avg_time) + '+/-' + str(std_time), str(avg_train) + '+/-' + str(std_train),\\\n",
    "str(avg_test) + '+/-' + str(std_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Façam estes pip install antes de correrem o resto, façam no anaconda prompt pa ser mais rapido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.777797Z",
     "start_time": "2020-12-12T11:22:57.768823Z"
    }
   },
   "outputs": [],
   "source": [
    "# in anaconda prompt: conda install python-graphviz\n",
    "# pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.825688Z",
     "start_time": "2020-12-12T11:22:57.780789Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "import pydotplus\n",
    "\n",
    "def plot_tree(model):\n",
    "    dot_data = export_graphviz(model,\n",
    "                               feature_names=X_train_tree.columns,  \n",
    "                               class_names=[\"High income\", \"Low income\"],\n",
    "                               filled=True)\n",
    "    pydot_graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    pydot_graph.set_size('\"20,20\"')\n",
    "    return graphviz.Source(pydot_graph.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.841626Z",
     "start_time": "2020-12-12T11:22:57.833648Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_results(df, *args):\n",
    "    \"\"\"\n",
    "    Receive an empty dataframe and the different models and call the function avg_score\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    # for each model passed as argument\n",
    "    for arg in args:\n",
    "        # obtain the results provided by avg_score\n",
    "        time, avg_train, avg_test = avg_score(arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = time, avg_train, avg_test\n",
    "        count+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos exprimentar primeiro com o gini e depois com entropy tmb vou pesquizar a diferença para não estarmos a fazer cenas a toa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.917425Z",
     "start_time": "2020-12-12T11:22:57.845624Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_gini = DecisionTreeClassifier()\n",
    "dt_gini.fit(X_train_tree, y_train)\n",
    "y_pred = dt_gini.predict(X_test_tree)\n",
    "y_pred_prob = dt_gini.predict_proba(X_test_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:57.933380Z",
     "start_time": "2020-12-12T11:22:57.922411Z"
    }
   },
   "outputs": [],
   "source": [
    "print('The defined three has a depth of ' + str(dt_gini.get_depth()) + ', ' + str(dt_gini.tree_.node_count) + \n",
    "      ' nodes and a total of ' + str(dt_gini.get_n_leaves()) + ' leaves.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:58.010185Z",
     "start_time": "2020-12-12T11:22:57.936373Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_entropy = DecisionTreeClassifier(criterion = 'entropy').fit(X_train_tree, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:58.285242Z",
     "start_time": "2020-12-12T11:22:58.018156Z"
    }
   },
   "outputs": [],
   "source": [
    "yes=avg_score(dt_entropy)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:58.837553Z",
     "start_time": "2020-12-12T11:22:58.288193Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Test'], index = ['Gini','Entropy'])\n",
    "show_results(df,dt_gini, dt_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gini tem valores ligeiramente mais elevados no test que entropy por isso vou prosseguir com esse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:59.083919Z",
     "start_time": "2020-12-12T11:22:58.848519Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range (1, 32):\n",
    "    dt_curr = DecisionTreeClassifier(max_depth = i).fit(X_train_tree, y_train)\n",
    "    \n",
    "    print('The current depth is ' , i)\n",
    "    print('The train score is :', avg_score(dt_curr)[1])\n",
    "    print('The test score is :', avg_score(dt_curr)[2])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A depth ideal seria de 8, 9 ou 10 mais do que isso estamos a incorrer em overfitting, sugiro 8 tem valores muito equilibrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Minimum number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:59.101873Z",
     "start_time": "2020-12-12T11:21:49.200Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range (50, 1000,50):\n",
    "    dt_curr = DecisionTreeClassifier(min_samples_split = i).fit(X_train_tree, y_train)\n",
    "    \n",
    "    print('The current depth is ' , i)\n",
    "    print('The train score is :', avg_score(dt_curr)[1])\n",
    "    print('The test score is :', avg_score(dt_curr)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto que nao parece mudar muito não vou considerar este parametro, o score oscila quase que aleatoriamente "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight of each leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:59.103867Z",
     "start_time": "2020-12-12T11:21:49.431Z"
    }
   },
   "outputs": [],
   "source": [
    "a=np.arange(0.05,0.5,0.05) \n",
    "\n",
    "for i in range (len(a)):\n",
    "    dt_curr = DecisionTreeClassifier(min_weight_fraction_leaf = a[i]).fit(X_train_tree, y_train)\n",
    "    \n",
    "    print('The leaft weight is ' , a[i])\n",
    "    print('The train score is :', avg_score(dt_curr)[1])\n",
    "    print('The test score is :', avg_score(dt_curr)[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com estes tre parametros conseguimos então reduzir o over fittin e esta seria a arvore final:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:59.105862Z",
     "start_time": "2020-12-12T11:21:49.626Z"
    }
   },
   "outputs": [],
   "source": [
    "dt_final = DecisionTreeClassifier(min_weight_fraction_leaf = 0.05, max_features = 8,min_samples_split = 100).fit(X_train_tree, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:59.109856Z",
     "start_time": "2020-12-12T11:21:49.742Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['Time','Train','Test'], index = ['Final tree'])\n",
    "show_results(df,dt_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-12T11:22:59.114840Z",
     "start_time": "2020-12-12T11:21:49.957Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_tree(dt_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEm16Yh3s3vF"
   },
   "source": [
    "# **Final Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUQsB_S1s5yY"
   },
   "source": [
    "# **Assess**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HFo0KYYbs8FQ"
   },
   "source": [
    "# **Limitations and Conclusions**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ML_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "272px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
